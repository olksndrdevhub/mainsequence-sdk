{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Introduction to the Main Sequence Python SDK","text":"<p>The Main Sequence Python SDK is a powerful set of client libraries designed to facilitate interaction with Main Sequence systems using Python. The SDK covers four main components:</p> <ol> <li>TDAG: A Time Series Data Orchestration and Scheduling Tool.</li> <li>Client: The Main Sequence client for interacting with the Main Sequence API.</li> <li>VirtualFundBuilder: A collection of classes and methods to quickly build portfolios and interact with our AI agents.</li> <li>Examples: A comprehensive collection of examples demonstrating how to build portfolios and interact with our AI agents.</li> </ol>"},{"location":"#how-the-documentation-is-organized","title":"How the Documentation is Organized","text":"<p>The documentation follows the same structure as the SDK. Within each topic, we delve deeper into the logic and usage.</p> <p>Additionally, we provide an extensive set of examples within the repository here: Example Repository.</p> <p>The examples section is organized by use-case rather than by individual libraries.</p> <p>You can find a full video tutorial here: Example Repository.</p> <p>Recordings of our previous bootcamps are also available here: Example Repository.</p>"},{"location":"about/","title":"About","text":"<p>TDAG is proprietary software that is part of the MainSequence SDK and is developed for use only under an explicit license agreement. The details of the license are as follows:</p> <p>MainSequence GmbH SDK License Agreement This License Agreement (the \"License\") governs the use, modification, and distribution of the software provided by MainSequence GmbH (the \"Licensor\"). The software (the \"Software\") is provided to you under the terms of this License. By using the Software, you agree to the terms of this License.</p> <p>TERMS AND CONDITIONS</p> <ol> <li>Definitions    \"Personal Use\": Use by an individual for personal purposes that are not connected to any business, organization, or    commercial activity.    \"Internal Use\": Use within a business, organization, or other entity, provided it is not made accessible to third    parties or used for commercial purposes.    \"Commercial Use\": Use of the Software in exchange for monetary or other compensation, including hosting, offering    Software as a service, selling the Software, or using it in a product or service for sale.    \"License Agreement\": The legally binding agreement between the Licensor and the licensee (you), subject to the terms    outlined in this License.</li> <li>Grant of License    1.1 Personal and Internal Use    The Licensor grants you a limited, non-exclusive, non-transferable, revocable license to use and modify the Software    for personal or internal use only, provided that such use is strictly subject to this License Agreement and continues    only while the License Agreement remains in effect.    Upon termination of this License Agreement, all rights to use the Software for personal or internal purposes shall be    immediately revoked, and you must cease all use of the Software.    1.2 Modification    You are permitted to modify the Software solely for your own personal or internal use, subject to the restrictions    outlined in this License Agreement.    You are not permitted to distribute, sublicense, or otherwise transfer modified or unmodified versions of the    Software to any third party.    1.3 Prohibited Redistribution    You may not redistribute, sublicense, sell, lease, rent, or otherwise transfer the Software, whether in its original    form or as modified by you, to any third party.    Any attempt to distribute or transfer the Software in any way, without explicit permission from MainSequence GmbH, is    strictly prohibited.</li> <li>Prohibition of Commercial Use    The Software may not be used for any commercial purposes without obtaining a separate commercial license from    MainSequence GmbH.    Examples of prohibited commercial use include, but are not limited to:    Hosting or offering the Software as a service to others, either modified or unmodified.    Using the Software as part of a commercial product or service provided to customers for a fee.    Using the Software in any production environment that generates income, directly or indirectly, from its use.</li> <li>Termination    This License Agreement will automatically terminate if you fail to comply with any of its terms.    Upon termination of this License, you must immediately cease all use of the Software, destroy all copies (modified or    unmodified), and remove the Software from any devices or systems on which it is installed.    MainSequence GmbH reserves the right to terminate this License at its discretion for any violation of its terms or    for any other reason.</li> <li>Commercial License    If you wish to use the Software for commercial purposes, you must contact MainSequence GmbH to negotiate and obtain a    separate commercial license. The terms of the commercial license, including any fees, will be negotiated separately    from this License Agreement.    Without a valid commercial license, you are strictly prohibited from using the Software for any commercial activity.</li> <li> <p>Disclaimer of Warranty    THE SOFTWARE IS PROVIDED \"AS IS\" WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE    WARRANTIES OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE, AND NONINFRINGEMENT. IN NO EVENT SHALL MAINSEQUENCE    GMBH OR THE COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES, OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT,    TORT, OR OTHERWISE, ARISING FROM, OUT OF, OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE    SOFTWARE.</p> </li> <li> <p>Limitation of Liability    IN NO EVENT SHALL MAINSEQUENCE GMBH BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, OR CONSEQUENTIAL DAMAGES    ARISING OUT OF THE USE OR INABILITY TO USE THE SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGES.</p> </li> <li> <p>Governing Law    This License Agreement shall be governed by and construed in accordance with the laws of the jurisdiction where MainSequence GmbH is located, without regard to its conflict of law provisions.</p> </li> </ol>"},{"location":"changelog/","title":"Changelog","text":""},{"location":"contact_and_support/","title":"Contact &amp; Support","text":""},{"location":"/home/jose/code/MainSequenceClientSide/mainsequence-sdk/docs/reference/logconf/","title":"Logconf","text":""},{"location":"/home/jose/code/MainSequenceClientSide/mainsequence-sdk/docs/reference/logconf/#mainsequence.logconf","title":"<code>mainsequence.logconf</code>","text":""},{"location":"/home/jose/code/MainSequenceClientSide/mainsequence-sdk/docs/reference/logconf/#mainsequence.logconf.build_application_logger","title":"<code>build_application_logger(application_name='ms-sdk', **metadata)</code>","text":"<p>Create a logger that logs to console and file in JSON format.</p>"},{"location":"/home/jose/code/MainSequenceClientSide/mainsequence-sdk/docs/reference/logconf/#mainsequence.logconf.extract_from_record","title":"<code>extract_from_record(_, __, event_dict)</code>","text":"<p>Extract thread and process names and add them to the event dict.</p>"},{"location":"/home/jose/code/MainSequenceClientSide/mainsequence-sdk/docs/reference/client/ai/","title":"Ai","text":""},{"location":"/home/jose/code/MainSequenceClientSide/mainsequence-sdk/docs/reference/client/ai/#mainsequence.client.ai","title":"<code>mainsequence.client.ai</code>","text":""},{"location":"/home/jose/code/MainSequenceClientSide/mainsequence-sdk/docs/reference/client/base/","title":"Base","text":""},{"location":"/home/jose/code/MainSequenceClientSide/mainsequence-sdk/docs/reference/client/base/#mainsequence.client.base","title":"<code>mainsequence.client.base</code>","text":""},{"location":"/home/jose/code/MainSequenceClientSide/mainsequence-sdk/docs/reference/client/base/#mainsequence.client.base.BaseObjectOrm","title":"<code>BaseObjectOrm</code>","text":""},{"location":"/home/jose/code/MainSequenceClientSide/mainsequence-sdk/docs/reference/client/base/#mainsequence.client.base.BaseObjectOrm.filter","title":"<code>filter(timeout=None, **kwargs)</code>  <code>classmethod</code>","text":"<p>Fetches all pages from a DRF-paginated endpoint. Accumulates results from each page until 'next' is None.</p> <p>Returns a list of <code>cls</code> objects (not just one page).</p> <p>DRF's typical paginated response looks like:     {       \"count\": ,       \"next\": ,       \"previous\": ,       \"results\": [ ...items... ]     }"},{"location":"/home/jose/code/MainSequenceClientSide/mainsequence-sdk/docs/reference/client/base/#mainsequence.client.base.BaseObjectOrm.get","title":"<code>get(pk=None, timeout=None, **filters)</code>  <code>classmethod</code>","text":"<p>Retrieves exactly one object by primary key: GET /base_url// Raises <code>DoesNotExist</code> if 404 or the response is empty. Raises Exception if multiple or unexpected data is returned."},{"location":"/home/jose/code/MainSequenceClientSide/mainsequence-sdk/docs/reference/client/models_helpers/","title":"Models helpers","text":""},{"location":"/home/jose/code/MainSequenceClientSide/mainsequence-sdk/docs/reference/client/models_helpers/#mainsequence.client.models_helpers","title":"<code>mainsequence.client.models_helpers</code>","text":""},{"location":"/home/jose/code/MainSequenceClientSide/mainsequence-sdk/docs/reference/client/models_helpers/#mainsequence.client.models_helpers.AssetCategory","title":"<code>AssetCategory</code>","text":"<p>               Bases: <code>BaseObjectOrm</code>, <code>BasePydanticModel</code></p>"},{"location":"/home/jose/code/MainSequenceClientSide/mainsequence-sdk/docs/reference/client/models_helpers/#mainsequence.client.models_helpers.AssetCategory.append_assets","title":"<code>append_assets(asset_ids)</code>","text":"<p>Append the given asset IDs to this category. Expects a payload: {\"assets\": [, , ...]}"},{"location":"/home/jose/code/MainSequenceClientSide/mainsequence-sdk/docs/reference/client/models_helpers/#mainsequence.client.models_helpers.AssetCategory.remove_assets","title":"<code>remove_assets(asset_ids)</code>","text":"<p>Remove the given asset IDs from this category. Expects a payload: {\"assets\": [, , ...]}"},{"location":"/home/jose/code/MainSequenceClientSide/mainsequence-sdk/docs/reference/client/models_helpers/#mainsequence.client.models_helpers.AssetMixin","title":"<code>AssetMixin</code>","text":"<p>               Bases: <code>BaseObjectOrm</code>, <code>BasePydanticModel</code></p>"},{"location":"/home/jose/code/MainSequenceClientSide/mainsequence-sdk/docs/reference/client/models_helpers/#mainsequence.client.models_helpers.AssetMixin.filter_with_asset_class","title":"<code>filter_with_asset_class(timeout=None, *args, **kwargs)</code>  <code>classmethod</code>","text":"<p>Filters assets and returns instances with their correct asset class, looping through all DRF-paginated pages.</p>"},{"location":"/home/jose/code/MainSequenceClientSide/mainsequence-sdk/docs/reference/client/models_helpers/#mainsequence.client.models_helpers.AssetMixin.get_ccxt_symbol","title":"<code>get_ccxt_symbol(settlement_symbol=None)</code>","text":"<p>Gets the right symbol for ccxt</p>"},{"location":"/home/jose/code/MainSequenceClientSide/mainsequence-sdk/docs/reference/client/models_helpers/#mainsequence.client.models_helpers.BaseObjectOrm","title":"<code>BaseObjectOrm</code>","text":""},{"location":"/home/jose/code/MainSequenceClientSide/mainsequence-sdk/docs/reference/client/models_helpers/#mainsequence.client.models_helpers.BaseObjectOrm.filter","title":"<code>filter(timeout=None, **kwargs)</code>  <code>classmethod</code>","text":"<p>Fetches all pages from a DRF-paginated endpoint. Accumulates results from each page until 'next' is None.</p> <p>Returns a list of <code>cls</code> objects (not just one page).</p> <p>DRF's typical paginated response looks like:     {       \"count\": ,       \"next\": ,       \"previous\": ,       \"results\": [ ...items... ]     }"},{"location":"/home/jose/code/MainSequenceClientSide/mainsequence-sdk/docs/reference/client/models_helpers/#mainsequence.client.models_helpers.BaseObjectOrm.get","title":"<code>get(pk=None, timeout=None, **filters)</code>  <code>classmethod</code>","text":"<p>Retrieves exactly one object by primary key: GET /base_url// Raises <code>DoesNotExist</code> if 404 or the response is empty. Raises Exception if multiple or unexpected data is returned."},{"location":"/home/jose/code/MainSequenceClientSide/mainsequence-sdk/docs/reference/client/models_helpers/#mainsequence.client.models_helpers.HistoricalWeights","title":"<code>HistoricalWeights</code>","text":"<p>               Bases: <code>BaseObjectOrm</code>, <code>BasePydanticModel</code></p>"},{"location":"/home/jose/code/MainSequenceClientSide/mainsequence-sdk/docs/reference/client/models_helpers/#mainsequence.client.models_helpers.HistoricalWeights.add_from_time_serie","title":"<code>add_from_time_serie(local_time_serie_id, positions_list, weights_date, comments=None, timeout=None)</code>  <code>classmethod</code>","text":"<p>:param session: :return:</p>"},{"location":"/home/jose/code/MainSequenceClientSide/mainsequence-sdk/docs/reference/client/models_helpers/#mainsequence.client.models_helpers.get_model_class","title":"<code>get_model_class(model_class)</code>","text":"<p>Reverse look from model class by name</p>"},{"location":"/home/jose/code/MainSequenceClientSide/mainsequence-sdk/docs/reference/client/models_tdag/","title":"Models tdag","text":""},{"location":"/home/jose/code/MainSequenceClientSide/mainsequence-sdk/docs/reference/client/models_tdag/#mainsequence.client.models_tdag","title":"<code>mainsequence.client.models_tdag</code>","text":""},{"location":"/home/jose/code/MainSequenceClientSide/mainsequence-sdk/docs/reference/client/models_tdag/#mainsequence.client.models_tdag.DataUpdates","title":"<code>DataUpdates</code>","text":"<p>               Bases: <code>BaseModel</code></p> <p>TODO WIP Helper function to work with the table updates</p>"},{"location":"/home/jose/code/MainSequenceClientSide/mainsequence-sdk/docs/reference/client/models_tdag/#mainsequence.client.models_tdag.DataUpdates.__iter__","title":"<code>__iter__()</code>","text":"<p>Iterate over keys.</p>"},{"location":"/home/jose/code/MainSequenceClientSide/mainsequence-sdk/docs/reference/client/models_tdag/#mainsequence.client.models_tdag.DynamicTableDataSource","title":"<code>DynamicTableDataSource</code>","text":"<p>               Bases: <code>BasePydanticModel</code>, <code>BaseObjectOrm</code></p>"},{"location":"/home/jose/code/MainSequenceClientSide/mainsequence-sdk/docs/reference/client/models_tdag/#mainsequence.client.models_tdag.DynamicTableDataSource.coerce_related_resource","title":"<code>coerce_related_resource(value)</code>","text":"<p>Decide if <code>value</code> should be parsed into a specific subclass of BaseDataSource. This runs before the standard validation.</p>"},{"location":"/home/jose/code/MainSequenceClientSide/mainsequence-sdk/docs/reference/client/models_tdag/#mainsequence.client.models_tdag.DynamicTableDataSource.model_dump_json","title":"<code>model_dump_json(**json_dumps_kwargs)</code>","text":"<p>Dump the current instance to a JSON string, ensuring that the dependent <code>related_resource</code> is also properly dumped.</p>"},{"location":"/home/jose/code/MainSequenceClientSide/mainsequence-sdk/docs/reference/client/models_tdag/#mainsequence.client.models_tdag.DynamicTableHelpers","title":"<code>DynamicTableHelpers</code>","text":""},{"location":"/home/jose/code/MainSequenceClientSide/mainsequence-sdk/docs/reference/client/models_tdag/#mainsequence.client.models_tdag.DynamicTableHelpers.get_update_statistics","title":"<code>get_update_statistics(hash_id)</code>","text":"<p>Gets latest value from Hash_id</p>"},{"location":"/home/jose/code/MainSequenceClientSide/mainsequence-sdk/docs/reference/client/models_tdag/#mainsequence.client.models_tdag.LocalTimeSerie","title":"<code>LocalTimeSerie</code>","text":"<p>               Bases: <code>BasePydanticModel</code>, <code>BaseObjectOrm</code></p>"},{"location":"/home/jose/code/MainSequenceClientSide/mainsequence-sdk/docs/reference/client/models_tdag/#mainsequence.client.models_tdag.LocalTimeSerie.get_data_between_dates_from_api","title":"<code>get_data_between_dates_from_api(start_date, end_date, great_or_equal, less_or_equal, unique_identifier_list, columns, unique_identifier_range_map)</code>","text":"<p>Helper function to make a single batch request (or multiple paged requests if next_offset).</p>"},{"location":"/home/jose/code/MainSequenceClientSide/mainsequence-sdk/docs/reference/client/models_tdag/#mainsequence.client.models_tdag.LocalTimeSerie.get_metadatas_and_set_updates","title":"<code>get_metadatas_and_set_updates(local_time_series_ids, update_details_kwargs, update_priority_dict)</code>  <code>classmethod</code>","text":"<p>{'local_hash_id__in': [{'local_hash_id': 'alpacaequitybarstest_97018e7280c1bad321b3f4153cc7e986', 'data_source_id': 1}, :param local_hash_id__in: :param multi_index_asset_symbols_filter: :param update_details_kwargs: :param update_priority_dict: :return:</p>"},{"location":"/home/jose/code/MainSequenceClientSide/mainsequence-sdk/docs/reference/client/models_tdag/#mainsequence.client.models_tdag.LocalTimeSerie.post_data_frame_in_chunks","title":"<code>post_data_frame_in_chunks(serialized_data_frame, chunk_size=50000, local_metadata=None, data_source=None, index_names=None, time_index_name='timestamp', overwrite=False)</code>  <code>classmethod</code>","text":"<p>Sends a large DataFrame to a Django backend in multiple chunks.</p> <p>:param serialized_data_frame: The DataFrame to upload. :param url: The endpoint URL (e.g. https://yourapi.com/upload-chunk/). :param chunk_size: Number of rows per chunk. :param local_metadata: General metadata dict you want to send with each chunk. :param data_source: Additional info about the source of the data. :param index_names: Index columns in the DataFrame. :param time_index_name: The column name used for time indexing. :param overwrite: Boolean indicating whether existing data should be overwritten.</p>"},{"location":"/home/jose/code/MainSequenceClientSide/mainsequence-sdk/docs/reference/client/models_tdag/#mainsequence.client.models_tdag.LocalTimeSerie.verify_if_direct_dependencies_are_updated","title":"<code>verify_if_direct_dependencies_are_updated()</code>","text":"<p>Response({     \"error_on_update_dependencies\": False,     \"updated\": all_success, })</p>"},{"location":"/home/jose/code/MainSequenceClientSide/mainsequence-sdk/docs/reference/client/models_tdag/#mainsequence.client.models_tdag.Scheduler","title":"<code>Scheduler</code>","text":"<p>               Bases: <code>BasePydanticModel</code>, <code>BaseObjectOrm</code></p>"},{"location":"/home/jose/code/MainSequenceClientSide/mainsequence-sdk/docs/reference/client/models_tdag/#mainsequence.client.models_tdag.Scheduler.stop_heart_beat","title":"<code>stop_heart_beat()</code>","text":"<p>Stop the heartbeat gracefully.</p>"},{"location":"/home/jose/code/MainSequenceClientSide/mainsequence-sdk/docs/reference/client/models_tdag/#mainsequence.client.models_tdag.SourceTableConfiguration","title":"<code>SourceTableConfiguration</code>","text":"<p>               Bases: <code>BasePydanticModel</code>, <code>BaseObjectOrm</code></p>"},{"location":"/home/jose/code/MainSequenceClientSide/mainsequence-sdk/docs/reference/client/models_tdag/#mainsequence.client.models_tdag.SourceTableConfiguration.patch_column_metadata","title":"<code>patch_column_metadata(column_metadata)</code>","text":""},{"location":"/home/jose/code/MainSequenceClientSide/mainsequence-sdk/docs/reference/client/models_tdag/#mainsequence.client.models_tdag.none_if_backend_detached","title":"<code>none_if_backend_detached(func)</code>","text":"<p>Decorator that evaluates BACKEND_DETACHED before executing the function. If BACKEND_DETACHED() returns True, the function is skipped, and None is returned. Otherwise, the function is executed as normal.</p> <p>It supports regular functions, property methods, classmethods, and staticmethods.</p>"},{"location":"/home/jose/code/MainSequenceClientSide/mainsequence-sdk/docs/reference/client/models_vam/","title":"Models vam","text":""},{"location":"/home/jose/code/MainSequenceClientSide/mainsequence-sdk/docs/reference/client/models_vam/#mainsequence.client.models_vam","title":"<code>mainsequence.client.models_vam</code>","text":""},{"location":"/home/jose/code/MainSequenceClientSide/mainsequence-sdk/docs/reference/client/models_vam/#mainsequence.client.models_vam.AssetCategory","title":"<code>AssetCategory</code>","text":"<p>               Bases: <code>BaseObjectOrm</code>, <code>BasePydanticModel</code></p>"},{"location":"/home/jose/code/MainSequenceClientSide/mainsequence-sdk/docs/reference/client/models_vam/#mainsequence.client.models_vam.AssetCategory.append_assets","title":"<code>append_assets(asset_ids)</code>","text":"<p>Append the given asset IDs to this category. Expects a payload: {\"assets\": [, , ...]}"},{"location":"/home/jose/code/MainSequenceClientSide/mainsequence-sdk/docs/reference/client/models_vam/#mainsequence.client.models_vam.AssetCategory.remove_assets","title":"<code>remove_assets(asset_ids)</code>","text":"<p>Remove the given asset IDs from this category. Expects a payload: {\"assets\": [, , ...]}"},{"location":"/home/jose/code/MainSequenceClientSide/mainsequence-sdk/docs/reference/client/models_vam/#mainsequence.client.models_vam.AssetMixin","title":"<code>AssetMixin</code>","text":"<p>               Bases: <code>BaseObjectOrm</code>, <code>BasePydanticModel</code></p>"},{"location":"/home/jose/code/MainSequenceClientSide/mainsequence-sdk/docs/reference/client/models_vam/#mainsequence.client.models_vam.AssetMixin.filter_with_asset_class","title":"<code>filter_with_asset_class(timeout=None, *args, **kwargs)</code>  <code>classmethod</code>","text":"<p>Filters assets and returns instances with their correct asset class, looping through all DRF-paginated pages.</p>"},{"location":"/home/jose/code/MainSequenceClientSide/mainsequence-sdk/docs/reference/client/models_vam/#mainsequence.client.models_vam.AssetMixin.get_ccxt_symbol","title":"<code>get_ccxt_symbol(settlement_symbol=None)</code>","text":"<p>Gets the right symbol for ccxt</p>"},{"location":"/home/jose/code/MainSequenceClientSide/mainsequence-sdk/docs/reference/client/models_vam/#mainsequence.client.models_vam.HistoricalWeights","title":"<code>HistoricalWeights</code>","text":"<p>               Bases: <code>BaseObjectOrm</code>, <code>BasePydanticModel</code></p>"},{"location":"/home/jose/code/MainSequenceClientSide/mainsequence-sdk/docs/reference/client/models_vam/#mainsequence.client.models_vam.HistoricalWeights.add_from_time_serie","title":"<code>add_from_time_serie(local_time_serie_id, positions_list, weights_date, comments=None, timeout=None)</code>  <code>classmethod</code>","text":"<p>:param session: :return:</p>"},{"location":"/home/jose/code/MainSequenceClientSide/mainsequence-sdk/docs/reference/client/utils/","title":"Utils","text":""},{"location":"/home/jose/code/MainSequenceClientSide/mainsequence-sdk/docs/reference/client/utils/#mainsequence.client.utils","title":"<code>mainsequence.client.utils</code>","text":""},{"location":"/home/jose/code/MainSequenceClientSide/mainsequence-sdk/docs/reference/client/utils/#mainsequence.client.utils.LazyConstants","title":"<code>LazyConstants</code>","text":"<p>               Bases: <code>dict</code></p> <p>Class Method to load constants only once they are called. this minimizes the calls to the API</p>"},{"location":"/home/jose/code/MainSequenceClientSide/mainsequence-sdk/docs/reference/client/utils/#mainsequence.client.utils.LazyConstants.to_attr_dict","title":"<code>to_attr_dict(data)</code>","text":"<p>Recursively convert a Python dict into an object that allows dot-notation access. Non-dict values (e.g., int, str, list) are returned as-is; dicts become _AttrDict.</p>"},{"location":"/home/jose/code/MainSequenceClientSide/mainsequence-sdk/docs/reference/client/utils/#mainsequence.client.utils.is_process_running","title":"<code>is_process_running(pid)</code>","text":"<p>Check if a process with the given PID is running.</p> <p>Args:     pid (int): The process ID to check.</p> <p>Returns:     bool: True if the process is running, False otherwise.</p>"},{"location":"/home/jose/code/MainSequenceClientSide/mainsequence-sdk/docs/reference/client/data_sources_interfaces/local_data_lake/","title":"Local data lake","text":""},{"location":"/home/jose/code/MainSequenceClientSide/mainsequence-sdk/docs/reference/client/data_sources_interfaces/local_data_lake/#mainsequence.client.data_sources_interfaces.local_data_lake","title":"<code>mainsequence.client.data_sources_interfaces.local_data_lake</code>","text":""},{"location":"/home/jose/code/MainSequenceClientSide/mainsequence-sdk/docs/reference/client/data_sources_interfaces/local_data_lake/#mainsequence.client.data_sources_interfaces.local_data_lake.DataLakeInterface","title":"<code>DataLakeInterface</code>","text":""},{"location":"/home/jose/code/MainSequenceClientSide/mainsequence-sdk/docs/reference/client/data_sources_interfaces/local_data_lake/#mainsequence.client.data_sources_interfaces.local_data_lake.DataLakeInterface.build_time_and_symbol_filter","title":"<code>build_time_and_symbol_filter(start_date=None, great_or_equal=True, less_or_equal=True, end_date=None, unique_identifier_list=None, unique_identifier_range_map=None)</code>  <code>staticmethod</code>","text":"<p>Build hashable parquet filters based on the parameters.</p> <p>Args:     metadata (dict): Metadata dictionary, not used for filtering here but included for extensibility.     start_date (datetime.datetime, optional): Start date for filtering.     great_or_equal (bool): Whether the start date condition is <code>&gt;=</code> or <code>&gt;</code>.     less_or_equal (bool): Whether the end date condition is <code>&lt;=</code> or <code>&lt;</code>.     end_date (datetime.datetime, optional): End date for filtering.     asset_symbols (list, optional): List of asset symbols to filter on.</p> <p>Returns:     tuple: Hashable parquet filters for use with pandas or pyarrow.</p>"},{"location":"/home/jose/code/MainSequenceClientSide/mainsequence-sdk/docs/reference/client/data_sources_interfaces/local_data_lake/#mainsequence.client.data_sources_interfaces.local_data_lake.DataLakeInterface.filter_by_assets_ranges","title":"<code>filter_by_assets_ranges(table_name, asset_ranges_map)</code>","text":"<p>:param table_name: :param asset_ranges_map: :return:</p>"},{"location":"/home/jose/code/MainSequenceClientSide/mainsequence-sdk/docs/reference/client/data_sources_interfaces/local_data_lake/#mainsequence.client.data_sources_interfaces.local_data_lake.DataLakeInterface.persist_datalake","title":"<code>persist_datalake(data, overwrite, table_name, time_index_name, index_names)</code>","text":"<p>Partition per week , do not partition per asset_symbol as system only allows 1024 partittions Args:     data:</p> <p>Returns:</p>"},{"location":"/home/jose/code/MainSequenceClientSide/mainsequence-sdk/docs/reference/client/data_sources_interfaces/local_data_lake/#mainsequence.client.data_sources_interfaces.local_data_lake.DataLakeInterface.query_datalake","title":"<code>query_datalake(table_name, filters=None)</code>","text":"<p>Queries the data lake for time series data.</p> <p>If the table_hash is in nodes_to_persist, it retrieves or creates the data. Otherwise, it updates the series from the source.</p> <p>Args:     ts: The time series object.     latest_value: The latest timestamp to query from.     symbol_list: List of symbols to retrieve data for.     great_or_equal: Boolean flag for date comparison.     update_tree_kwargs: Dictionary of kwargs for updating the tree.</p> <p>Returns:     pd.DataFrame: The queried data.</p>"},{"location":"/home/jose/code/MainSequenceClientSide/mainsequence-sdk/docs/reference/client/data_sources_interfaces/local_data_lake/#mainsequence.client.data_sources_interfaces.local_data_lake.memory_usage_exceeds_limit","title":"<code>memory_usage_exceeds_limit(max_usage_percentage)</code>","text":"<p>Checks if the current memory usage exceeds the given percentage of total memory.</p>"},{"location":"/home/jose/code/MainSequenceClientSide/mainsequence-sdk/docs/reference/client/data_sources_interfaces/local_data_lake/#mainsequence.client.data_sources_interfaces.local_data_lake.read_full_data","title":"<code>read_full_data(file_path, filters=None, use_s3_if_available=False, max_memory_usage=80)</code>  <code>cached</code>","text":"<p>Cached access to static datalake file</p>"},{"location":"/home/jose/code/MainSequenceClientSide/mainsequence-sdk/docs/reference/client/data_sources_interfaces/timescale/","title":"Timescale","text":""},{"location":"/home/jose/code/MainSequenceClientSide/mainsequence-sdk/docs/reference/client/data_sources_interfaces/timescale/#mainsequence.client.data_sources_interfaces.timescale","title":"<code>mainsequence.client.data_sources_interfaces.timescale</code>","text":""},{"location":"/home/jose/code/MainSequenceClientSide/mainsequence-sdk/docs/reference/client/data_sources_interfaces/timescale/#mainsequence.client.data_sources_interfaces.timescale.direct_data_from_db","title":"<code>direct_data_from_db(local_metadata, connection_uri, start_date=None, great_or_equal=True, less_or_equal=True, end_date=None, columns=None, unique_identifier_list=None, unique_identifier_range_map=None)</code>","text":"<p>Connects directly to the DB without passing through the ORM to speed up calculations.</p> <p>Parameters:</p> Name Type Description Default <code>metadata</code> <code>dict</code> <p>Metadata containing table and column details.</p> required <code>connection_config</code> <code>dict</code> <p>Connection configuration for the database.</p> required <code>start_date</code> <code>datetime</code> <p>The start date for filtering. If None, no lower bound is applied.</p> <code>None</code> <code>great_or_equal</code> <code>bool</code> <p>Whether the start_date filter is inclusive (&gt;=). Defaults to True.</p> <code>True</code> <code>less_or_equal</code> <code>bool</code> <p>Whether the end_date filter is inclusive (&lt;=). Defaults to True.</p> <code>True</code> <code>end_date</code> <code>datetime</code> <p>The end date for filtering. If None, no upper bound is applied.</p> <code>None</code> <code>columns</code> <code>list</code> <p>Specific columns to select. If None, all columns are selected.</p> <code>None</code> <p>Returns:</p> Type Description <code>DataFrame</code> <p>Data from the table as a pandas DataFrame, optionally filtered by date range.</p>"},{"location":"/home/jose/code/MainSequenceClientSide/mainsequence-sdk/docs/reference/client/data_sources_interfaces/timescale/#mainsequence.client.data_sources_interfaces.timescale.direct_table_update","title":"<code>direct_table_update(metadata, serialized_data_frame, overwrite, grouped_dates, table_is_empty, time_series_orm_db_connection=None, use_chunks=True, num_threads=4)</code>","text":"<p>Updates the database table with the given DataFrame.</p> <p>Parameters: - table_name: Name of the database table. - serialized_data_frame: DataFrame containing the data to insert. - overwrite: If True, existing data in the date range will be deleted before insertion. - time_index_name: Name of the time index column. - index_names: List of index column names. - table_is_empty: If True, the table is empty. - time_series_orm_db_connection: Database connection string. - use_chunks: If True, data will be inserted in chunks using threads. - num_threads: Number of threads to use when use_chunks is True.</p>"},{"location":"/home/jose/code/MainSequenceClientSide/mainsequence-sdk/docs/reference/client/data_sources_interfaces/timescale/#mainsequence.client.data_sources_interfaces.timescale.filter_by_assets_ranges","title":"<code>filter_by_assets_ranges(table_name, asset_ranges_map, index_names, data_source, column_types)</code>","text":"<p>Query time series data dynamically based on asset ranges.</p> <p>Args:     table_name (str): The name of the table to query.     asset_ranges_map (dict): A dictionary where keys are asset symbols and values are dictionaries containing:                              - 'start_date' (datetime): The start date of the range.                              - 'start_date_operand' (str): The SQL operand for the start date (e.g., '&gt;=' or '&gt;').                              - 'end_date' (datetime or None): The end date of the range.     index_names (list): List of column names to set as the DataFrame index.     data_source: A data source object with a method <code>get_connection_uri()</code> to get the database connection URI.</p> <p>Returns:     pd.DataFrame: A Pandas DataFrame with the queried data, indexed by the specified columns.</p>"},{"location":"/home/jose/code/MainSequenceClientSide/mainsequence-sdk/docs/reference/client/data_sources_interfaces/timescale/#mainsequence.client.data_sources_interfaces.timescale.process_and_update_table","title":"<code>process_and_update_table(serialized_data_frame, local_metadata, grouped_dates, data_source, index_names, time_index_name, overwrite=False, JSON_COMPRESSED_PREFIX=None)</code>","text":"<p>Process a serialized DataFrame, handle overwriting, and update a database table.</p> <p>Args:     serialized_data_frame (pd.DataFrame): The DataFrame to process and update.     metadata (DynamicTableMetaData): Metadata about the table, including table configuration.     grouped_dates (list): List of grouped dates to assist with the update.     data_source (object): A data source object with a <code>get_connection_uri</code> method.     index_names (list): List of index column names.     time_index_name (str): The name of the time index column.     overwrite (bool): Whether to overwrite the table or not.     JSON_COMPRESSED_PREFIX (list): List of prefixes to identify JSON-compressed columns.</p> <p>Returns:     None</p>"},{"location":"/home/jose/code/MainSequenceClientSide/mainsequence-sdk/docs/reference/instrumentation/utils/","title":"Utils","text":""},{"location":"/home/jose/code/MainSequenceClientSide/mainsequence-sdk/docs/reference/instrumentation/utils/#mainsequence.instrumentation.utils","title":"<code>mainsequence.instrumentation.utils</code>","text":""},{"location":"/home/jose/code/MainSequenceClientSide/mainsequence-sdk/docs/reference/instrumentation/utils/#mainsequence.instrumentation.utils.OTelJSONRenderer","title":"<code>OTelJSONRenderer</code>","text":"<p>               Bases: <code>JSONRenderer</code></p> <p>A custom JSON renderer that injects OTel trace/span fields immediately before serializing to JSON.</p>"},{"location":"/home/jose/code/MainSequenceClientSide/mainsequence-sdk/docs/reference/instrumentation/utils/#mainsequence.instrumentation.utils.TracerInstrumentator","title":"<code>TracerInstrumentator</code>","text":""},{"location":"/home/jose/code/MainSequenceClientSide/mainsequence-sdk/docs/reference/instrumentation/utils/#mainsequence.instrumentation.utils.TracerInstrumentator.build_tracer","title":"<code>build_tracer()</code>","text":"<p>buidl_tracer(\"Time Series\",name) :return:</p>"},{"location":"/home/jose/code/MainSequenceClientSide/mainsequence-sdk/docs/reference/instrumentation/utils/#mainsequence.instrumentation.utils.add_otel_trace_context","title":"<code>add_otel_trace_context(logger, method_name, event_dict)</code>","text":"<p>Enrich log records with OpenTelemetry trace context (trace_id, span_id).</p>"},{"location":"/home/jose/code/MainSequenceClientSide/mainsequence-sdk/docs/reference/tdag/config/","title":"Config","text":""},{"location":"/home/jose/code/MainSequenceClientSide/mainsequence-sdk/docs/reference/tdag/config/#mainsequence.tdag.config","title":"<code>mainsequence.tdag.config</code>","text":""},{"location":"/home/jose/code/MainSequenceClientSide/mainsequence-sdk/docs/reference/tdag/utils/","title":"Utils","text":""},{"location":"/home/jose/code/MainSequenceClientSide/mainsequence-sdk/docs/reference/tdag/utils/#mainsequence.tdag.utils","title":"<code>mainsequence.tdag.utils</code>","text":""},{"location":"/home/jose/code/MainSequenceClientSide/mainsequence-sdk/docs/reference/tdag/utils/#mainsequence.tdag.utils.copy_drop_database","title":"<code>copy_drop_database(source_uri, target_uri, source_container_name)</code>","text":"<p>Copies database from one host to the other and guarantees  that  are no broken time series.</p> <p>Parameters:</p> Name Type Description Default <code>source_uri</code> <code>str</code> required <code>target_uri</code> <code>str</code> required <code>source_container_name</code> <code>str</code> required"},{"location":"/home/jose/code/MainSequenceClientSide/mainsequence-sdk/docs/reference/tdag/distributed/time_series/","title":"Time series","text":""},{"location":"/home/jose/code/MainSequenceClientSide/mainsequence-sdk/docs/reference/tdag/distributed/time_series/#mainsequence.tdag.distributed.time_series","title":"<code>mainsequence.tdag.distributed.time_series</code>","text":""},{"location":"/home/jose/code/MainSequenceClientSide/mainsequence-sdk/docs/reference/tdag/distributed/time_series/#mainsequence.tdag.distributed.time_series.MLflowTrackingRestApi","title":"<code>MLflowTrackingRestApi</code>","text":""},{"location":"/home/jose/code/MainSequenceClientSide/mainsequence-sdk/docs/reference/tdag/distributed/time_series/#mainsequence.tdag.distributed.time_series.MLflowTrackingRestApi.get_all_finished_runs_df","title":"<code>get_all_finished_runs_df(experiment_name, include_running=False)</code>","text":"<p>Parameters:</p> Name Type Description Default <code>experiment_name</code> <code>str</code> required <code>include_running</code> <code>False</code>"},{"location":"/home/jose/code/MainSequenceClientSide/mainsequence-sdk/docs/reference/tdag/distributed/utils/","title":"Utils","text":""},{"location":"/home/jose/code/MainSequenceClientSide/mainsequence-sdk/docs/reference/tdag/distributed/utils/#mainsequence.tdag.distributed.utils","title":"<code>mainsequence.tdag.distributed.utils</code>","text":""},{"location":"/home/jose/code/MainSequenceClientSide/mainsequence-sdk/docs/reference/tdag/distributed/utils/#mainsequence.tdag.distributed.utils.get_request_status_from_query","title":"<code>get_request_status_from_query(query, request_url)</code>","text":"<p>:param query: :type query: :return: :rtype:</p>"},{"location":"/home/jose/code/MainSequenceClientSide/mainsequence-sdk/docs/reference/tdag/time_series/persist_managers/","title":"Persist managers","text":""},{"location":"/home/jose/code/MainSequenceClientSide/mainsequence-sdk/docs/reference/tdag/time_series/persist_managers/#mainsequence.tdag.time_series.persist_managers","title":"<code>mainsequence.tdag.time_series.persist_managers</code>","text":""},{"location":"/home/jose/code/MainSequenceClientSide/mainsequence-sdk/docs/reference/tdag/time_series/persist_managers/#mainsequence.tdag.time_series.persist_managers.DataLakePersistManager","title":"<code>DataLakePersistManager</code>","text":"<p>               Bases: <code>PersistManager</code></p> <p>A class to manage data persistence in a local data lake.</p> <p>This class handles the storage and retrieval of time series data in a local file system, organized by date ranges and table hashes.</p>"},{"location":"/home/jose/code/MainSequenceClientSide/mainsequence-sdk/docs/reference/tdag/time_series/persist_managers/#mainsequence.tdag.time_series.persist_managers.DataLakePersistManager.__init__","title":"<code>__init__(*args, **kwargs)</code>","text":"<p>Initializes the DataLakePersistManager with configuration from environment variables.</p>"},{"location":"/home/jose/code/MainSequenceClientSide/mainsequence-sdk/docs/reference/tdag/time_series/persist_managers/#mainsequence.tdag.time_series.persist_managers.DataLakePersistManager.set_already_run","title":"<code>set_already_run(already_run)</code>","text":"<p>This methos is critical as it control the level of introspection and avouids recursivity        This happens for example when TimeSeries.update(,): TimeSeries.update(latest_value,,**):     self.get_update_statistics() &lt;- will incurr in a circular refefence using local data late Args:     introspection:</p> <p>Returns:</p>"},{"location":"/home/jose/code/MainSequenceClientSide/mainsequence-sdk/docs/reference/tdag/time_series/persist_managers/#mainsequence.tdag.time_series.persist_managers.DataLakePersistManager.verify_if_already_run","title":"<code>verify_if_already_run(ts)</code>","text":"<p>This method handles all the configuration and setup necessary when running a detached local data lake :param ts: :return:</p>"},{"location":"/home/jose/code/MainSequenceClientSide/mainsequence-sdk/docs/reference/tdag/time_series/persist_managers/#mainsequence.tdag.time_series.persist_managers.PersistManager","title":"<code>PersistManager</code>","text":""},{"location":"/home/jose/code/MainSequenceClientSide/mainsequence-sdk/docs/reference/tdag/time_series/persist_managers/#mainsequence.tdag.time_series.persist_managers.PersistManager.build_update_details","title":"<code>build_update_details(source_class_name)</code>","text":""},{"location":"/home/jose/code/MainSequenceClientSide/mainsequence-sdk/docs/reference/tdag/time_series/persist_managers/#mainsequence.tdag.time_series.persist_managers.PersistManager.depends_on_connect","title":"<code>depends_on_connect(new_ts, is_api)</code>","text":"<p>Connects a time Serie as relationship in the DB</p> <p>Parameters:</p> Name Type Description Default <code>new_ts</code> <code>TimeSerie</code> required"},{"location":"/home/jose/code/MainSequenceClientSide/mainsequence-sdk/docs/reference/tdag/time_series/persist_managers/#mainsequence.tdag.time_series.persist_managers.PersistManager.get_persisted_ts","title":"<code>get_persisted_ts()</code>","text":"<p>full Request of the persisted data should always default to DB :return:</p>"},{"location":"/home/jose/code/MainSequenceClientSide/mainsequence-sdk/docs/reference/tdag/time_series/persist_managers/#mainsequence.tdag.time_series.persist_managers.PersistManager.local_persist_exist_set_config","title":"<code>local_persist_exist_set_config(remote_table_hashed_name, local_configuration, remote_configuration, data_source, time_serie_source_code_git_hash, time_serie_source_code, remote_build_metadata)</code>","text":"<p>This method runs on initialization of the TimeSerie class. We also use it to retrieve the table if is already persisted :param config:</p> <p>:return:</p>"},{"location":"/home/jose/code/MainSequenceClientSide/mainsequence-sdk/docs/reference/tdag/time_series/persist_managers/#mainsequence.tdag.time_series.persist_managers.PersistManager.patch_build_configuration","title":"<code>patch_build_configuration(local_configuration, remote_configuration, remote_build_metadata)</code>","text":"<p>Args:     local_configuration:     remote_configuration:</p> <p>Returns:</p>"},{"location":"/home/jose/code/MainSequenceClientSide/mainsequence-sdk/docs/reference/tdag/time_series/persist_managers/#mainsequence.tdag.time_series.persist_managers.PersistManager.patch_update_details","title":"<code>patch_update_details(local_hash_id=None, **kwargs)</code>","text":"<p>Patch update details ofr related_table</p> <p>Parameters:</p> Name Type Description Default <code>hash_id</code> required <code>kwargs</code> <code>{}</code>"},{"location":"/home/jose/code/MainSequenceClientSide/mainsequence-sdk/docs/reference/tdag/time_series/persist_managers/#mainsequence.tdag.time_series.persist_managers.PersistManager.persist_updated_data","title":"<code>persist_updated_data(temp_df, historical_update_id, update_tracker=None, overwrite=False)</code>","text":"<p>Main update time series function, it is called from TimeSeries class</p> <p>Parameters:</p> Name Type Description Default <code>temp_df</code> <code>DataFrame</code> required <code>latest_value</code> required <code>session</code> required"},{"location":"/home/jose/code/MainSequenceClientSide/mainsequence-sdk/docs/reference/tdag/time_series/persist_managers/#mainsequence.tdag.time_series.persist_managers.PersistManager.synchronize_metadata","title":"<code>synchronize_metadata(meta_data, local_metadata, set_last_index_value=False, class_name=None)</code>","text":"<p>forces a synchronization between table and metadata :return:</p>"},{"location":"/home/jose/code/MainSequenceClientSide/mainsequence-sdk/docs/reference/tdag/time_series/persist_managers/#mainsequence.tdag.time_series.persist_managers.PersistManager.update_source_informmation","title":"<code>update_source_informmation(git_hash_id, source_code)</code>","text":"<p>Args:     git_hash_id:     source_code:</p> <p>Returns:</p>"},{"location":"/home/jose/code/MainSequenceClientSide/mainsequence-sdk/docs/reference/tdag/time_series/persist_managers/#mainsequence.tdag.time_series.persist_managers.TimeScaleLocalPersistManager","title":"<code>TimeScaleLocalPersistManager</code>","text":"<p>               Bases: <code>PersistManager</code></p> <p>Main Controler to interacti with TimeSerie ORM</p>"},{"location":"/home/jose/code/MainSequenceClientSide/mainsequence-sdk/docs/reference/tdag/time_series/persist_managers/#mainsequence.tdag.time_series.persist_managers.TimeScaleLocalPersistManager.get_full_source_data","title":"<code>get_full_source_data(remote_table_hash_id, engine='pandas')</code>","text":"<p>Returns full stored data, uses multiprocessing to achieve several queries by rows and speed :return:</p>"},{"location":"/home/jose/code/MainSequenceClientSide/mainsequence-sdk/docs/reference/tdag/time_series/time_series/","title":"Time series","text":""},{"location":"/home/jose/code/MainSequenceClientSide/mainsequence-sdk/docs/reference/tdag/time_series/time_series/#mainsequence.tdag.time_series.time_series","title":"<code>mainsequence.tdag.time_series.time_series</code>","text":""},{"location":"/home/jose/code/MainSequenceClientSide/mainsequence-sdk/docs/reference/tdag/time_series/time_series/#mainsequence.tdag.time_series.time_series.APITimeSerie","title":"<code>APITimeSerie</code>","text":"<p>               Bases: <code>CommonMethodsMixin</code></p>"},{"location":"/home/jose/code/MainSequenceClientSide/mainsequence-sdk/docs/reference/tdag/time_series/time_series/#mainsequence.tdag.time_series.time_series.APITimeSerie.__init__","title":"<code>__init__(data_source_id, local_hash_id, data_source_local_lake=None)</code>","text":"<p>A time serie is uniquely identified in tdag by  data_source_id and table_name :param data_source_id: :param table_name:</p>"},{"location":"/home/jose/code/MainSequenceClientSide/mainsequence-sdk/docs/reference/tdag/time_series/time_series/#mainsequence.tdag.time_series.time_series.APITimeSerie.build_from_unique_identifier","title":"<code>build_from_unique_identifier(unique_identifier)</code>  <code>classmethod</code>","text":"<p>:param vam_source_name: :return:</p>"},{"location":"/home/jose/code/MainSequenceClientSide/mainsequence-sdk/docs/reference/tdag/time_series/time_series/#mainsequence.tdag.time_series.time_series.APITimeSerie.filter_by_assets_ranges","title":"<code>filter_by_assets_ranges(unique_identifier_range_map)</code>","text":"<p>Parameters:</p> Name Type Description Default <code>asset_ranges</code> required"},{"location":"/home/jose/code/MainSequenceClientSide/mainsequence-sdk/docs/reference/tdag/time_series/time_series/#mainsequence.tdag.time_series.time_series.APITimeSerie.get_update_statistics","title":"<code>get_update_statistics(asset_symbols=None)</code>","text":"<p>getts latest value directly from querying the DB, args and kwargs are nedeed for datalake</p> <p>Parameters:</p> Name Type Description Default <code>args</code> required <code>kwargs</code> required"},{"location":"/home/jose/code/MainSequenceClientSide/mainsequence-sdk/docs/reference/tdag/time_series/time_series/#mainsequence.tdag.time_series.time_series.APITimeSerie.persist_data_to_local_lake","title":"<code>persist_data_to_local_lake(temp_df, update_tracker, latest_value, overwrite=False)</code>","text":"<p>Helper series to  persist data to a local lake for reading purposes :param temp_df: :param update_tracker: :param latest_value: :param overwrite: :return:</p>"},{"location":"/home/jose/code/MainSequenceClientSide/mainsequence-sdk/docs/reference/tdag/time_series/time_series/#mainsequence.tdag.time_series.time_series.ConfigSerializer","title":"<code>ConfigSerializer</code>","text":""},{"location":"/home/jose/code/MainSequenceClientSide/mainsequence-sdk/docs/reference/tdag/time_series/time_series/#mainsequence.tdag.time_series.time_series.ConfigSerializer.deserialize_pickle_state","title":"<code>deserialize_pickle_state(state, include_vam_client_objects, data_source_id, graph_depth_limit, graph_depth)</code>  <code>classmethod</code>","text":"<p>Parameters:</p> Name Type Description Default <code>state</code> required <code>deserialize_pickle_state</code> required"},{"location":"/home/jose/code/MainSequenceClientSide/mainsequence-sdk/docs/reference/tdag/time_series/time_series/#mainsequence.tdag.time_series.time_series.ConfigSerializer.rebuild_config","title":"<code>rebuild_config(config, ignore_pydantic=False)</code>  <code>classmethod</code>","text":"<p>:param config: :return:</p>"},{"location":"/home/jose/code/MainSequenceClientSide/mainsequence-sdk/docs/reference/tdag/time_series/time_series/#mainsequence.tdag.time_series.time_series.ConfigSerializer.rebuild_pydantic_model","title":"<code>rebuild_pydantic_model(details, state_kwargs=None)</code>  <code>classmethod</code>","text":"<p>If there is an state rebuild the configuration then the method to rebuild related objects is from state Args:     details:      state_kwargs: </p> <p>Returns:</p>"},{"location":"/home/jose/code/MainSequenceClientSide/mainsequence-sdk/docs/reference/tdag/time_series/time_series/#mainsequence.tdag.time_series.time_series.ConfigSerializer.rebuild_serialized_config","title":"<code>rebuild_serialized_config(config, time_serie_class_name)</code>  <code>classmethod</code>","text":"<p>rebulds configuration from config file, particularly Assets :param config:</p> <p>:param time_serie_class_name: :return:</p>"},{"location":"/home/jose/code/MainSequenceClientSide/mainsequence-sdk/docs/reference/tdag/time_series/time_series/#mainsequence.tdag.time_series.time_series.ConfigSerializer.rebuild_serialized_wrapper_dict","title":"<code>rebuild_serialized_wrapper_dict(time_series_dict_config)</code>  <code>classmethod</code>","text":"<p>rebuilds configuration from time_series Wrapper :param time_series_dict_config:</p> <p>:return:</p>"},{"location":"/home/jose/code/MainSequenceClientSide/mainsequence-sdk/docs/reference/tdag/time_series/time_series/#mainsequence.tdag.time_series.time_series.ConfigSerializer.serialize_init_kwargs","title":"<code>serialize_init_kwargs(kwargs)</code>","text":"<p>serializes  TimeSeries init_kwargs to be able to  persist in local configuration :param kwargs: :return:</p>"},{"location":"/home/jose/code/MainSequenceClientSide/mainsequence-sdk/docs/reference/tdag/time_series/time_series/#mainsequence.tdag.time_series.time_series.DataPersistanceMethods","title":"<code>DataPersistanceMethods</code>","text":"<p>               Bases: <code>ABC</code></p>"},{"location":"/home/jose/code/MainSequenceClientSide/mainsequence-sdk/docs/reference/tdag/time_series/time_series/#mainsequence.tdag.time_series.time_series.DataPersistanceMethods.filter_by_assets_ranges","title":"<code>filter_by_assets_ranges(asset_ranges_map)</code>","text":"<p>Parameters:</p> Name Type Description Default <code>asset_ranges</code> required"},{"location":"/home/jose/code/MainSequenceClientSide/mainsequence-sdk/docs/reference/tdag/time_series/time_series/#mainsequence.tdag.time_series.time_series.DataPersistanceMethods.flush_local_persisted","title":"<code>flush_local_persisted(flush_only_time_series=True, session=None)</code>","text":"<p>deletes  persisted data :param flush_sub_folders: :return:</p>"},{"location":"/home/jose/code/MainSequenceClientSide/mainsequence-sdk/docs/reference/tdag/time_series/time_series/#mainsequence.tdag.time_series.time_series.DataPersistanceMethods.get_last_observation","title":"<code>get_last_observation(unique_identifier_list=None)</code>","text":"<p>(1) Requests last observatiion from local persist manager (3) evaluates if last observation is consistent</p>"},{"location":"/home/jose/code/MainSequenceClientSide/mainsequence-sdk/docs/reference/tdag/time_series/time_series/#mainsequence.tdag.time_series.time_series.DataPersistanceMethods.get_latest_update_by_assets_filter","title":"<code>get_latest_update_by_assets_filter(asset_symbols, last_update_per_asset)</code>","text":"<p>Gets the latest update from a symbol list :param asset_symbols: :return:</p>"},{"location":"/home/jose/code/MainSequenceClientSide/mainsequence-sdk/docs/reference/tdag/time_series/time_series/#mainsequence.tdag.time_series.time_series.DataPersistanceMethods.get_update_statistics","title":"<code>get_update_statistics(unique_identifier_list=None)</code>","text":"<p>gets latest value directly from querying the DB, args and kwargs are nedeed for datalake</p>"},{"location":"/home/jose/code/MainSequenceClientSide/mainsequence-sdk/docs/reference/tdag/time_series/time_series/#mainsequence.tdag.time_series.time_series.DataPersistanceMethods.update_details_in_dependecy_tree","title":"<code>update_details_in_dependecy_tree(set_relation_tree=True, include_head=False, *args, **kwargs)</code>","text":"<p>updates schedule from all tree related time series :param schedule: :return:</p>"},{"location":"/home/jose/code/MainSequenceClientSide/mainsequence-sdk/docs/reference/tdag/time_series/time_series/#mainsequence.tdag.time_series.time_series.DataPersistanceMethods.upsert_data","title":"<code>upsert_data(data_df)</code>","text":"<p>Updates and Insert data into DB :param data_df: :return:</p>"},{"location":"/home/jose/code/MainSequenceClientSide/mainsequence-sdk/docs/reference/tdag/time_series/time_series/#mainsequence.tdag.time_series.time_series.GraphNodeMethods","title":"<code>GraphNodeMethods</code>","text":"<p>               Bases: <code>ABC</code></p>"},{"location":"/home/jose/code/MainSequenceClientSide/mainsequence-sdk/docs/reference/tdag/time_series/time_series/#mainsequence.tdag.time_series.time_series.GraphNodeMethods.get_all_local_dependencies","title":"<code>get_all_local_dependencies()</code>","text":"<p>get relation tree by ids in the graph :return:</p>"},{"location":"/home/jose/code/MainSequenceClientSide/mainsequence-sdk/docs/reference/tdag/time_series/time_series/#mainsequence.tdag.time_series.time_series.GraphNodeMethods.get_update_map","title":"<code>get_update_map(dependecy_map=None)</code>","text":"<p>Obtain all local time_series in the dependency graph by introspecting the code :return:</p>"},{"location":"/home/jose/code/MainSequenceClientSide/mainsequence-sdk/docs/reference/tdag/time_series/time_series/#mainsequence.tdag.time_series.time_series.GraphNodeMethods.set_relation_tree","title":"<code>set_relation_tree()</code>","text":"<p>Sets relationhsip in the DB :return:</p>"},{"location":"/home/jose/code/MainSequenceClientSide/mainsequence-sdk/docs/reference/tdag/time_series/time_series/#mainsequence.tdag.time_series.time_series.ModelList","title":"<code>ModelList</code>","text":"<p>               Bases: <code>list</code></p> <p>Necessary for configuration</p>"},{"location":"/home/jose/code/MainSequenceClientSide/mainsequence-sdk/docs/reference/tdag/time_series/time_series/#mainsequence.tdag.time_series.time_series.TimeSerie","title":"<code>TimeSerie</code>","text":"<p>               Bases: <code>CommonMethodsMixin</code>, <code>DataPersistanceMethods</code>, <code>GraphNodeMethods</code>, <code>TimeSerieRebuildMethods</code></p> <p>Pipeline</p> <pre><code>-__init__\n- _create_config\n\n- _init_db_properties_config\n- set_graph node\n</code></pre>"},{"location":"/home/jose/code/MainSequenceClientSide/mainsequence-sdk/docs/reference/tdag/time_series/time_series/#mainsequence.tdag.time_series.time_series.TimeSerie.hash_id","title":"<code>hash_id</code>  <code>property</code>","text":"<p>Returns:</p>"},{"location":"/home/jose/code/MainSequenceClientSide/mainsequence-sdk/docs/reference/tdag/time_series/time_series/#mainsequence.tdag.time_series.time_series.TimeSerie.__init__","title":"<code>__init__(init_meta=None, build_meta_data=None, local_kwargs_to_ignore=None, *args, **kwargs)</code>","text":"<p>Initializes the TimeSerie object with the provided metadata and configurations.</p> <p>This method sets up the time series object, loading the necessary configurations and metadata. If <code>is_local_relation_tree_set</code> is True, it avoids recalculating the relationship tree in schedulers, optimizing the process if the tree is already calculated during initialization.</p> <p>Parameters:</p> Name Type Description Default <code>init_meta</code> <code>dict</code> <p>Metadata for initializing the time series instance.</p> <code>None</code> <code>build_meta_data</code> <code>dict</code> <p>Metadata related to the building process of the time series.</p> <code>None</code> <code>local_kwargs_to_ignore</code> <code>list</code> <p>List of keyword arguments to ignore during configuration.</p> <code>None</code> <code>*args</code> <code>tuple</code> <p>Additional arguments.</p> <code>()</code> <code>**kwargs</code> <code>dict</code> <p>Additional keyword arguments.</p> <code>{}</code>"},{"location":"/home/jose/code/MainSequenceClientSide/mainsequence-sdk/docs/reference/tdag/time_series/time_series/#mainsequence.tdag.time_series.time_series.TimeSerie.get_html_description","title":"<code>get_html_description()</code>","text":"<p>must return a descript on html tags so it can be readable and rendedered Returns:</p>"},{"location":"/home/jose/code/MainSequenceClientSide/mainsequence-sdk/docs/reference/tdag/time_series/time_series/#mainsequence.tdag.time_series.time_series.TimeSerie.get_time_serie_source_code_git_hash","title":"<code>get_time_serie_source_code_git_hash(TimeSerieClass)</code>  <code>staticmethod</code>","text":"<p>Hashes a time serie source code</p>"},{"location":"/home/jose/code/MainSequenceClientSide/mainsequence-sdk/docs/reference/tdag/time_series/time_series/#mainsequence.tdag.time_series.time_series.TimeSerie.patch_build_configuration","title":"<code>patch_build_configuration()</code>","text":"<p>This method comes in handy when there is a change in VAM models extra configuration. This method will properly update the models on all the tree</p>"},{"location":"/home/jose/code/MainSequenceClientSide/mainsequence-sdk/docs/reference/tdag/time_series/time_series/#mainsequence.tdag.time_series.time_series.TimeSerie.pre_update_setting_routines","title":"<code>pre_update_setting_routines(scheduler, set_time_serie_queue_status, update_tree, metadata=None, local_metadata=None)</code>","text":"<p>Routines to execute previous to an update</p>"},{"location":"/home/jose/code/MainSequenceClientSide/mainsequence-sdk/docs/reference/tdag/time_series/time_series/#mainsequence.tdag.time_series.time_series.TimeSerie.run","title":"<code>run(debug_mode, *, update_tree=True, force_update=False, update_only_tree=False, remote_scheduler=None)</code>","text":"<p>Args:     debug_mode: if the time serie is run in debug mode the DAG will be run node by node in the same process     update_tree: if set to False then only the selected time series will be run, default is True     force_update: Force an update even if the time serie schedule does not require an update     update_only_tree: If set to True then only the dependency graph of the selected time serie will be updated     remote_scheduler:</p>"},{"location":"/home/jose/code/MainSequenceClientSide/mainsequence-sdk/docs/reference/tdag/time_series/time_series/#mainsequence.tdag.time_series.time_series.TimeSerie.set_data_source","title":"<code>set_data_source(data_source=None)</code>","text":"<p>:return:</p>"},{"location":"/home/jose/code/MainSequenceClientSide/mainsequence-sdk/docs/reference/tdag/time_series/time_series/#mainsequence.tdag.time_series.time_series.TimeSerie.set_dependencies_df","title":"<code>set_dependencies_df()</code>","text":"<p>:return:</p>"},{"location":"/home/jose/code/MainSequenceClientSide/mainsequence-sdk/docs/reference/tdag/time_series/time_series/#mainsequence.tdag.time_series.time_series.TimeSerie.set_update_statistics","title":"<code>set_update_statistics(update_statistics)</code>","text":"<p>Default method to narrow down update statistics un local time series, the method will filter using asset_list if the attribute exists as well as the init fallback date :param update_statistics: :return:</p>"},{"location":"/home/jose/code/MainSequenceClientSide/mainsequence-sdk/docs/reference/tdag/time_series/time_series/#mainsequence.tdag.time_series.time_series.TimeSerie.update","title":"<code>update(update_statistics)</code>","text":""},{"location":"/home/jose/code/MainSequenceClientSide/mainsequence-sdk/docs/reference/tdag/time_series/time_series/#mainsequence.tdag.time_series.time_series.TimeSerieConfigKwargs","title":"<code>TimeSerieConfigKwargs</code>","text":"<p>               Bases: <code>dict</code></p> <p>Necessary class for configuration</p>"},{"location":"/home/jose/code/MainSequenceClientSide/mainsequence-sdk/docs/reference/tdag/time_series/time_series/#mainsequence.tdag.time_series.time_series.TimeSerieRebuildMethods","title":"<code>TimeSerieRebuildMethods</code>","text":"<p>               Bases: <code>ABC</code></p>"},{"location":"/home/jose/code/MainSequenceClientSide/mainsequence-sdk/docs/reference/tdag/time_series/time_series/#mainsequence.tdag.time_series.time_series.TimeSerieRebuildMethods.get_minimum_required_depth_for_update","title":"<code>get_minimum_required_depth_for_update()</code>","text":"<p>Controls the minimum depth that needs to be rebuil</p>"},{"location":"/home/jose/code/MainSequenceClientSide/mainsequence-sdk/docs/reference/tdag/time_series/time_series/#mainsequence.tdag.time_series.time_series.TimeSerieRebuildMethods.persist_to_pickle","title":"<code>persist_to_pickle(overwrite=False)</code>","text":"<p>:return: :rtype:</p>"},{"location":"/home/jose/code/MainSequenceClientSide/mainsequence-sdk/docs/reference/tdag/time_series/time_series/#mainsequence.tdag.time_series.time_series.TimeSerieRebuildMethods.rebuild_and_set_from_local_hash_id","title":"<code>rebuild_and_set_from_local_hash_id(local_hash_id, data_source_id, set_dependencies_df=False, graph_depth_limit=1)</code>  <code>classmethod</code>","text":"<p>:param local_hash_id: :param data_source_id: :param set_dependencies_df: :param graph_depth_limit: :param local_metadatas: :return:</p>"},{"location":"/home/jose/code/MainSequenceClientSide/mainsequence-sdk/docs/reference/tdag/time_series/time_series/#mainsequence.tdag.time_series.time_series.TimeSerieRebuildMethods.rebuild_from_configuration","title":"<code>rebuild_from_configuration(local_hash_id, data_source)</code>  <code>classmethod</code>","text":"<p>:param serie_data_folder:</p> <p>:return: TimeSerie</p>"},{"location":"/home/jose/code/MainSequenceClientSide/mainsequence-sdk/docs/reference/tdag/time_series/time_series/#mainsequence.tdag.time_series.time_series.TimeSerieRebuildMethods.run_in_debug_scheduler","title":"<code>run_in_debug_scheduler(break_after_one_update=True, run_head_in_main_process=True, wait_for_update=True, force_update=True, debug=True, update_tree=True, raise_exception_on_error=True)</code>","text":"<p>Args:     break_after_one_update:     run_head_in_main_process:     wait_for_update:     force_update:     debug:     update_tree:</p> <p>Returns:</p>"},{"location":"/home/jose/code/MainSequenceClientSide/mainsequence-sdk/docs/reference/tdag/time_series/time_series/#mainsequence.tdag.time_series.time_series.TimeSerieRebuildMethods.set_state_with_sessions","title":"<code>set_state_with_sessions(include_vam_client_objects=True, graph_depth_limit=1000, graph_depth=0)</code>","text":"<p>Method to set state after it was loaded from pickle.</p> <p>Parameters:</p> Name Type Description Default <code>include_vam_client_objects</code> <code>True</code> <code>graph_depth_limit</code> <code>1000</code> <code>metadatas</code> <code>pre-requestd dictionary of metadatas to speed calculation of rebuild of state</code> required <code>graph_depth</code> <code>0</code>"},{"location":"/home/jose/code/MainSequenceClientSide/mainsequence-sdk/docs/reference/tdag/time_series/time_series/#mainsequence.tdag.time_series.time_series.TimeSerieRebuildMethods.start_time_serie_update","title":"<code>start_time_serie_update(update_tracker, debug_mode, raise_exceptions=True, update_tree=False, local_time_series_map=None, update_only_tree=False, force_update=False, use_state_for_update=False)</code>","text":"<p>Main update method for time series that interacts with Graph node. Time series should be updated through this method only :param update_tree_kwargs: :param raise_exceptions: :param update_tree: :param scheduler: models.Scheduler :param metadatas: pre-requested metadatas to speed initiation of ts :return:</p>"},{"location":"/home/jose/code/MainSequenceClientSide/mainsequence-sdk/docs/reference/tdag/time_series/time_series/#mainsequence.tdag.time_series.time_series.WrapperTimeSerie","title":"<code>WrapperTimeSerie</code>","text":"<p>               Bases: <code>TimeSerie</code></p> <p>A wrapper class for managing multiple TimeSerie objects.</p>"},{"location":"/home/jose/code/MainSequenceClientSide/mainsequence-sdk/docs/reference/tdag/time_series/time_series/#mainsequence.tdag.time_series.time_series.WrapperTimeSerie.wrapped_latest_index_value","title":"<code>wrapped_latest_index_value: Dict[str, Any]</code>  <code>property</code>","text":"<p>Get the latest values of all wrapped TimeSeries.</p> <p>Returns:     A dictionary with keys corresponding to TimeSerie keys and values being their latest values.</p>"},{"location":"/home/jose/code/MainSequenceClientSide/mainsequence-sdk/docs/reference/tdag/time_series/time_series/#mainsequence.tdag.time_series.time_series.WrapperTimeSerie.wrapper_keys","title":"<code>wrapper_keys: List[str]</code>  <code>property</code>","text":"<p>Get the keys of all wrapped TimeSeries.</p> <p>Returns:     A list of keys for all wrapped TimeSeries.</p>"},{"location":"/home/jose/code/MainSequenceClientSide/mainsequence-sdk/docs/reference/tdag/time_series/time_series/#mainsequence.tdag.time_series.time_series.WrapperTimeSerie.__init__","title":"<code>__init__(time_series_dict, *args, **kwargs)</code>","text":"<p>Initialize the WrapperTimeSerie.</p> <p>Args:     time_series_dict: Dictionary of TimeSerie objects.</p>"},{"location":"/home/jose/code/MainSequenceClientSide/mainsequence-sdk/docs/reference/tdag/time_series/time_series/#mainsequence.tdag.time_series.time_series.WrapperTimeSerie.__setstate__","title":"<code>__setstate__(state)</code>","text":"<p>Restore instance attributes from a pickled state.</p>"},{"location":"/home/jose/code/MainSequenceClientSide/mainsequence-sdk/docs/reference/tdag/time_series/time_series/#mainsequence.tdag.time_series.time_series.WrapperTimeSerie.children_is_updating","title":"<code>children_is_updating()</code>","text":"<p>Check if any wrapped TimeSerie is currently updating.</p>"},{"location":"/home/jose/code/MainSequenceClientSide/mainsequence-sdk/docs/reference/tdag/time_series/time_series/#mainsequence.tdag.time_series.time_series.WrapperTimeSerie.get_pandas_df_list_data_greater_than","title":"<code>get_pandas_df_list_data_greater_than(target_value, great_or_equal, thread=True)</code>","text":"<p>Get DataFrames from all wrapped TimeSeries greater than a target value.</p> <p>Args:     target_value: The target datetime value to compare against.     great_or_equal: Whether to include the target value (True) or not (False).     thread: Whether to use threading for parallel processing.</p> <p>Returns:     A dictionary with TimeSerie keys and their corresponding DataFrames or error messages.</p>"},{"location":"/home/jose/code/MainSequenceClientSide/mainsequence-sdk/docs/reference/tdag/time_series/time_series/#mainsequence.tdag.time_series.time_series.WrapperTimeSerie.get_ts_as_pandas","title":"<code>get_ts_as_pandas()</code>","text":"<p>Get all wrapped TimeSeries as a list of pandas DataFrames.</p> <p>Returns:     A list of pandas DataFrames, one for each wrapped TimeSerie.</p>"},{"location":"/home/jose/code/MainSequenceClientSide/mainsequence-sdk/docs/reference/tdag/time_series/time_series/#mainsequence.tdag.time_series.time_series.WrapperTimeSerie.get_wrapped","title":"<code>get_wrapped()</code>","text":"<p>Get all wrapped TimeSeries, including nested ones.</p> <p>Returns:     A list of all wrapped TimeSerie objects, including those nested in other WrapperTimeSeries.</p>"},{"location":"/home/jose/code/MainSequenceClientSide/mainsequence-sdk/docs/reference/tdag/time_series/time_series/#mainsequence.tdag.time_series.time_series.WrapperTimeSerie.items","title":"<code>items()</code>","text":"<p>Get items of wrapped TimeSeries.</p>"},{"location":"/home/jose/code/MainSequenceClientSide/mainsequence-sdk/docs/reference/tdag/time_series/time_series/#mainsequence.tdag.time_series.time_series.WrapperTimeSerie.pandas_df_concat_on_rows_by_key_between_dates","title":"<code>pandas_df_concat_on_rows_by_key_between_dates(start_date=None, great_or_equal=None, end_date=None, less_or_equal=None, thread=False, unique_identifier_list=None, return_as_list=False, key_date_filter=None, unique_identifier_range_map=None)</code>","text":"<p>Concatenate DataFrames from all wrapped TimeSeries between given dates.</p> <p>Args:     start_date: The start date for the data range.     great_or_equal: Whether to include the start date (True) or not (False).     end_date: The end date for the data range.     less_or_equal: Whether to include the end date (True) or not (False).     thread: Whether to use threading for parallel processing.     unique_identifier_list: asset_symbol filter     return_as_list: If True, return a dictionary of DataFrames instead of concatenating.    key_date_filter: Concatenate DataFrames only for key date filter. Returns:     A concatenated DataFrame or a dictionary of DataFrames if return_as_list is True.</p>"},{"location":"/home/jose/code/MainSequenceClientSide/mainsequence-sdk/docs/reference/tdag/time_series/time_series/#mainsequence.tdag.time_series.time_series.WrapperTimeSerie.pandas_df_concat_on_rows_by_key_greater_than","title":"<code>pandas_df_concat_on_rows_by_key_greater_than(target_value, great_or_equal, thread=False, return_as_list=False, columns=None, *args, **kwargs)</code>","text":"<p>Concatenate DataFrames from all wrapped TimeSeries greater than a target value.</p> <p>Args:     target_value: The latest datetime value to compare against.     great_or_equal: Whether to include the target value (True) or not (False).     thread: Whether to use threading for parallel processing.     return_as_list: If True, return a dictionary of DataFrames instead of concatenating.     columns: Optional list of columns to include.</p> <p>Returns:     A concatenated DataFrame or a dictionary of DataFrames if return_as_list is True.</p>"},{"location":"/home/jose/code/MainSequenceClientSide/mainsequence-sdk/docs/reference/tdag/time_series/time_series/#mainsequence.tdag.time_series.time_series.WrapperTimeSerie.set_local_persist_manager_if_not_set","title":"<code>set_local_persist_manager_if_not_set()</code>","text":"<p>Set local persist manager for all wrapped TimeSeries.</p>"},{"location":"/home/jose/code/MainSequenceClientSide/mainsequence-sdk/docs/reference/tdag/time_series/time_series/#mainsequence.tdag.time_series.time_series.WrapperTimeSerie.set_state_with_sessions","title":"<code>set_state_with_sessions(include_vam_client_objects, graph_depth_limit, graph_depth)</code>","text":"<p>Set state with sessions for all wrapped TimeSeries.</p> <p>Args:     include_vam_client_objects: Whether to include asset ORM objects.     graph_depth_limit: The maximum depth of the graph to traverse.     graph_depth: The current depth in the graph.     local_metadatas: Optional metadata dictionary.</p>"},{"location":"/home/jose/code/MainSequenceClientSide/mainsequence-sdk/docs/reference/tdag/time_series/time_series/#mainsequence.tdag.time_series.time_series.WrapperTimeSerie.update","title":"<code>update(update_statistics)</code>","text":"<p>Implemented in the wrapped nodes</p>"},{"location":"/home/jose/code/MainSequenceClientSide/mainsequence-sdk/docs/reference/tdag/time_series/time_series/#mainsequence.tdag.time_series.time_series.WrapperTimeSerie.values","title":"<code>values()</code>","text":"<p>Get values of wrapped TimeSeries.</p>"},{"location":"/home/jose/code/MainSequenceClientSide/mainsequence-sdk/docs/reference/tdag/time_series/time_series/#mainsequence.tdag.time_series.time_series.hash_signature","title":"<code>hash_signature(dictionary)</code>","text":"<p>MD5 hash of a dictionary used to hash the local annd remote configuration of tables :param dictionary: :return:</p>"},{"location":"/home/jose/code/MainSequenceClientSide/mainsequence-sdk/docs/reference/tdag/time_series/utils/","title":"Utils","text":""},{"location":"/home/jose/code/MainSequenceClientSide/mainsequence-sdk/docs/reference/tdag/time_series/utils/#mainsequence.tdag.time_series.utils","title":"<code>mainsequence.tdag.time_series.utils</code>","text":""},{"location":"/home/jose/code/MainSequenceClientSide/mainsequence-sdk/docs/reference/tdag/time_series/update/api/","title":"Api","text":""},{"location":"/home/jose/code/MainSequenceClientSide/mainsequence-sdk/docs/reference/tdag/time_series/update/api/#mainsequence.tdag.time_series.update.api","title":"<code>mainsequence.tdag.time_series.update.api</code>","text":""},{"location":"/home/jose/code/MainSequenceClientSide/mainsequence-sdk/docs/reference/tdag/time_series/update/ray_manager/","title":"Ray manager","text":""},{"location":"/home/jose/code/MainSequenceClientSide/mainsequence-sdk/docs/reference/tdag/time_series/update/ray_manager/#mainsequence.tdag.time_series.update.ray_manager","title":"<code>mainsequence.tdag.time_series.update.ray_manager</code>","text":""},{"location":"/home/jose/code/MainSequenceClientSide/mainsequence-sdk/docs/reference/tdag/time_series/update/ray_manager/#mainsequence.tdag.time_series.update.ray_manager.RayUpdateManager","title":"<code>RayUpdateManager</code>","text":"<p>Controller for interactions with ray cluster</p>"},{"location":"/home/jose/code/MainSequenceClientSide/mainsequence-sdk/docs/reference/tdag/time_series/update/ray_manager/#mainsequence.tdag.time_series.update.ray_manager.RayUpdateManager.get_results_from_futures_list","title":"<code>get_results_from_futures_list(futures)</code>","text":"<p>should be a list of futures objects ray.remote() Args:     futures ():</p> <p>Returns:</p>"},{"location":"/home/jose/code/MainSequenceClientSide/mainsequence-sdk/docs/reference/tdag/time_series/update/scheduler/","title":"Scheduler","text":""},{"location":"/home/jose/code/MainSequenceClientSide/mainsequence-sdk/docs/reference/tdag/time_series/update/scheduler/#mainsequence.tdag.time_series.update.scheduler","title":"<code>mainsequence.tdag.time_series.update.scheduler</code>","text":""},{"location":"/home/jose/code/MainSequenceClientSide/mainsequence-sdk/docs/reference/tdag/time_series/update/scheduler/#mainsequence.tdag.time_series.update.scheduler.SchedulerUpdater","title":"<code>SchedulerUpdater</code>","text":""},{"location":"/home/jose/code/MainSequenceClientSide/mainsequence-sdk/docs/reference/tdag/time_series/update/scheduler/#mainsequence.tdag.time_series.update.scheduler.SchedulerUpdater.start","title":"<code>start(debug=False, update_tree=True, break_after_one_update=False, raise_exception_on_error=False, update_extra_kwargs=None, run_head_in_main_process=False, force_update=False, sequential_update=False, update_only_tree=False, api_port=None)</code>","text":"<p>Parameters:</p> Name Type Description Default <code>debug</code> <code>bool</code> <p>If True, all dependencies of a time series run in the same process. Defaults to False.</p> <code>False</code> <code>update_tree</code> <code>bool or dict</code> <p>If True, updates the tree of dependent tasks.</p> <code>True</code> <code>break_after_one_update</code> <code>bool</code> <p>If True, the process stops after the first update cycle. Defaults to False.</p> <code>False</code> <code>raise_exception_on_error</code> <code>bool</code> <p>If True, raises an exception on encountering an error during execution. Otherwise, errors are handled silently. Defaults to False.</p> <code>False</code> <code>update_extra_kwargs</code> <code>dict or None</code> <p>Additional parameters (if any) to pass along when updating. Defaults to None.</p> <code>None</code> <code>run_head_in_main_process</code> <code>bool</code> <p>If True, each \"head\" time series is run in the main scheduler process. Useful for debugging. Defaults to False.</p> <code>False</code> <code>force_update</code> <code>bool</code> <p>If True, forces an update run even if it's not required. Defaults to False.</p> <code>False</code> <code>sequential_update</code> <code>bool</code> <p>If True, runs each \"head\" time series one by one instead of in parallel. Defaults to False.</p> <code>False</code> <code>update_only_tree</code> <code>bool</code> <p>If True, only the dependency tree is updated without fully processing every step. Defaults to False.</p> <code>False</code> <code>api_port</code> <code>int or None</code> <p>The port on which any exposed APIs should run. If None, no API is exposed. Defaults to None.</p> <code>None</code>"},{"location":"/home/jose/code/MainSequenceClientSide/mainsequence-sdk/docs/reference/tdag/time_series/update/scheduler/#mainsequence.tdag.time_series.update.scheduler.TimeSerieHeadUpdateActor","title":"<code>TimeSerieHeadUpdateActor</code>","text":""},{"location":"/home/jose/code/MainSequenceClientSide/mainsequence-sdk/docs/reference/tdag/time_series/update/scheduler/#mainsequence.tdag.time_series.update.scheduler.TimeSerieHeadUpdateActor.__init__","title":"<code>__init__(local_hash_id, data_source_id, scheduler, debug, update_tree, update_extra_kwargs, remote_table_hashed_name)</code>","text":"<p>Parameters:</p> Name Type Description Default <code>hash_id</code> required <code>scheduler</code> <code>Scheduler</code> required <code>debug</code> required <code>update_tree</code> required <code>update_extra_kwargs</code> required"},{"location":"/home/jose/code/MainSequenceClientSide/mainsequence-sdk/docs/reference/tdag/time_series/update/scheduler/#mainsequence.tdag.time_series.update.scheduler.TimeSerieHeadUpdateActor.run_one_step_update","title":"<code>run_one_step_update(force_update=False, update_only_tree=False)</code>","text":"<p>Main update Method for a time serie Head</p>"},{"location":"/home/jose/code/MainSequenceClientSide/mainsequence-sdk/docs/reference/tdag/time_series/update/scheduler/#mainsequence.tdag.time_series.update.scheduler.set_data_source","title":"<code>set_data_source(pod_source=None, tdag_detached=False, override_all=False)</code>","text":"<p>:param override_all: :return:</p>"},{"location":"/home/jose/code/MainSequenceClientSide/mainsequence-sdk/docs/reference/tdag/time_series/update/update_methods/","title":"Update methods","text":""},{"location":"/home/jose/code/MainSequenceClientSide/mainsequence-sdk/docs/reference/tdag/time_series/update/update_methods/#mainsequence.tdag.time_series.update.update_methods","title":"<code>mainsequence.tdag.time_series.update.update_methods</code>","text":""},{"location":"/home/jose/code/MainSequenceClientSide/mainsequence-sdk/docs/reference/tdag/time_series/update/update_methods/#mainsequence.tdag.time_series.update.update_methods.TimeSerieUpdater","title":"<code>TimeSerieUpdater</code>","text":""},{"location":"/home/jose/code/MainSequenceClientSide/mainsequence-sdk/docs/reference/tdag/time_series/update/update_methods/#mainsequence.tdag.time_series.update.update_methods.update_remote_from_hash_id","title":"<code>update_remote_from_hash_id(*args, **kwargs)</code>","text":"<p>Ray wrapper for session update :param args: :param kwargs: :return:</p>"},{"location":"/home/jose/code/MainSequenceClientSide/mainsequence-sdk/docs/reference/tdag/time_series/update/update_methods/#mainsequence.tdag.time_series.update.update_methods.update_remote_from_hash_id_local","title":"<code>update_remote_from_hash_id_local(telemetry_carrier, scheduler_uid, local_time_serie_id, data_source_id, local_hash_id)</code>","text":"<p>Args:     in_update_tree_node_uid ():     update_tree_kwargs ():     execution_start ():     telemtry_carrier ():     update_priority ():     hash_id ():</p> <p>Returns:</p>"},{"location":"/home/jose/code/MainSequenceClientSide/mainsequence-sdk/docs/reference/tdag/time_series/update/utils/","title":"Utils","text":""},{"location":"/home/jose/code/MainSequenceClientSide/mainsequence-sdk/docs/reference/tdag/time_series/update/utils/#mainsequence.tdag.time_series.update.utils","title":"<code>mainsequence.tdag.time_series.update.utils</code>","text":""},{"location":"/home/jose/code/MainSequenceClientSide/mainsequence-sdk/docs/reference/tdag/time_series/update/utils/#mainsequence.tdag.time_series.update.utils.UpdateInterface","title":"<code>UpdateInterface</code>","text":"<p>Helper class to avoid calling ray in other modules</p>"},{"location":"/home/jose/code/MainSequenceClientSide/mainsequence-sdk/docs/reference/tdag/time_series/update/utils/#mainsequence.tdag.time_series.update.utils.get_available_port","title":"<code>get_available_port(port_range=(8000, 8090))</code>","text":"<p>Check if the given port is free, and if not, find an available port within the range.</p>"},{"location":"/home/jose/code/MainSequenceClientSide/mainsequence-sdk/docs/reference/tdag/time_series/update/utils/#mainsequence.tdag.time_series.update.utils.is_port_free","title":"<code>is_port_free(port)</code>","text":"<p>Check if the port is free on the local machine.</p>"},{"location":"/home/jose/code/MainSequenceClientSide/mainsequence-sdk/docs/reference/virtualfundbuilder/agent_interface/","title":"Agent interface","text":""},{"location":"/home/jose/code/MainSequenceClientSide/mainsequence-sdk/docs/reference/virtualfundbuilder/agent_interface/#mainsequence.virtualfundbuilder.agent_interface","title":"<code>mainsequence.virtualfundbuilder.agent_interface</code>","text":""},{"location":"/home/jose/code/MainSequenceClientSide/mainsequence-sdk/docs/reference/virtualfundbuilder/config_handling/","title":"Config handling","text":""},{"location":"/home/jose/code/MainSequenceClientSide/mainsequence-sdk/docs/reference/virtualfundbuilder/config_handling/#mainsequence.virtualfundbuilder.config_handling","title":"<code>mainsequence.virtualfundbuilder.config_handling</code>","text":""},{"location":"/home/jose/code/MainSequenceClientSide/mainsequence-sdk/docs/reference/virtualfundbuilder/config_handling/#mainsequence.virtualfundbuilder.config_handling.AssetMixin","title":"<code>AssetMixin</code>","text":"<p>               Bases: <code>BaseObjectOrm</code>, <code>BasePydanticModel</code></p>"},{"location":"/home/jose/code/MainSequenceClientSide/mainsequence-sdk/docs/reference/virtualfundbuilder/config_handling/#mainsequence.virtualfundbuilder.config_handling.AssetMixin.filter_with_asset_class","title":"<code>filter_with_asset_class(timeout=None, *args, **kwargs)</code>  <code>classmethod</code>","text":"<p>Filters assets and returns instances with their correct asset class, looping through all DRF-paginated pages.</p>"},{"location":"/home/jose/code/MainSequenceClientSide/mainsequence-sdk/docs/reference/virtualfundbuilder/config_handling/#mainsequence.virtualfundbuilder.config_handling.AssetMixin.get_ccxt_symbol","title":"<code>get_ccxt_symbol(settlement_symbol=None)</code>","text":"<p>Gets the right symbol for ccxt</p>"},{"location":"/home/jose/code/MainSequenceClientSide/mainsequence-sdk/docs/reference/virtualfundbuilder/config_handling/#mainsequence.virtualfundbuilder.config_handling.AssetMixinOverwrite","title":"<code>AssetMixinOverwrite</code>","text":"<p>               Bases: <code>VFBConfigBaseModel</code></p> <p>The Asset for evaluating the portfolio.</p> <p>Attributes:     symbol (str): The symbol of the asset.     execution_venue_symbol (ExecutionVenueNames): The execution venue where the asset traded. Needs to match with asset universe.</p>"},{"location":"/home/jose/code/MainSequenceClientSide/mainsequence-sdk/docs/reference/virtualfundbuilder/config_handling/#mainsequence.virtualfundbuilder.config_handling.AssetsConfiguration","title":"<code>AssetsConfiguration</code>","text":"<p>               Bases: <code>VFBConfigBaseModel</code></p> <p>Configuration for assets included in a portfolio.</p> <p>Attributes:     assets_category_unique_id (str):         Unique Identifier of assets category     price_type (PriceTypeNames): Type of price used for backtesting.     prices_configuration (PricesConfiguration): Configuration for price data handling.</p>"},{"location":"/home/jose/code/MainSequenceClientSide/mainsequence-sdk/docs/reference/virtualfundbuilder/config_handling/#mainsequence.virtualfundbuilder.config_handling.BacktestingWeightsConfig","title":"<code>BacktestingWeightsConfig</code>","text":"<p>               Bases: <code>VFBConfigBaseModel</code></p> <p>Configuration for backtesting weights.</p> <p>Attributes:     rebalance_strategy_name (str): Strategy used for rebalancing.     rebalance_strategy_configuration (Dict): Placeholder dict for the rebalance strategy configuration.     signal_weights_name (str): Type of signal weights strategy.     signal_weights_configuration (Dict): Placeholder dict for the signal weights configuration.</p>"},{"location":"/home/jose/code/MainSequenceClientSide/mainsequence-sdk/docs/reference/virtualfundbuilder/config_handling/#mainsequence.virtualfundbuilder.config_handling.MarketsTimeSeries","title":"<code>MarketsTimeSeries</code>","text":"<p>               Bases: <code>VFBConfigBaseModel</code></p> <p>MarketsTimeSeries based on their unique id. Used as the data sources for the prices. Values include alpaca_1d_bars, binance_1d_bars etc.</p> <p>Attributes:     unique_identifier (str): Identfier of the MarketsTimeSeries.</p>"},{"location":"/home/jose/code/MainSequenceClientSide/mainsequence-sdk/docs/reference/virtualfundbuilder/config_handling/#mainsequence.virtualfundbuilder.config_handling.ModelList","title":"<code>ModelList</code>","text":"<p>               Bases: <code>list</code></p> <p>Necessary for configuration</p>"},{"location":"/home/jose/code/MainSequenceClientSide/mainsequence-sdk/docs/reference/virtualfundbuilder/config_handling/#mainsequence.virtualfundbuilder.config_handling.PortfolioBuildConfiguration","title":"<code>PortfolioBuildConfiguration</code>","text":"<p>               Bases: <code>VFBConfigBaseModel</code></p> <p>Main class for configuring and building a portfolio.</p> <p>This class defines the configuration parameters needed for building a portfolio, including asset configurations, backtesting weights, and execution parameters.</p> <p>Attributes:     assets_configuration (AssetsConfiguration): Configuration details for assets.     portfolio_prices_frequency (str): Frequency to upsample portoflio. Optional.     backtesting_weights_configuration (BacktestingWeightsConfig): Weights configuration used for backtesting.     execution_configuration (PortfolioExecutionConfiguration): Execution settings for the portfolio.     valuation_asset (AssetMixin): The Asset for evaluating the portfolio.</p>"},{"location":"/home/jose/code/MainSequenceClientSide/mainsequence-sdk/docs/reference/virtualfundbuilder/config_handling/#mainsequence.virtualfundbuilder.config_handling.PortfolioConfiguration","title":"<code>PortfolioConfiguration</code>","text":"<p>               Bases: <code>VFBConfigBaseModel</code></p> <pre><code>Configuration for a complete portfolio, including build configuration,\nTDAG updates, and VAM settings.\n\nThis class aggregates different configurations required for the\nmanagement and operation of a portfolio.\n</code></pre> <p>Attributes:     portfolio_build_configuration (PortfolioBuildConfiguration): Configuration for building the portfolio.     portfolio_markets_configuration (PortfolioMarketsConfig): VAM execution configuration.</p>"},{"location":"/home/jose/code/MainSequenceClientSide/mainsequence-sdk/docs/reference/virtualfundbuilder/config_handling/#mainsequence.virtualfundbuilder.config_handling.PortfolioExecutionConfiguration","title":"<code>PortfolioExecutionConfiguration</code>","text":"<p>               Bases: <code>VFBConfigBaseModel</code></p> <p>Configuration for portfolio execution.</p> <p>Attributes:     commission_fee (float): Commission fee percentage.</p>"},{"location":"/home/jose/code/MainSequenceClientSide/mainsequence-sdk/docs/reference/virtualfundbuilder/config_handling/#mainsequence.virtualfundbuilder.config_handling.PortfolioMarketsConfig","title":"<code>PortfolioMarketsConfig</code>","text":"<p>               Bases: <code>VFBConfigBaseModel</code></p> <p>Configuration for Virtual Asset Management (VAM) portfolio.</p> <p>Attributes:     portfolio_name (str): Name of the portfolio.     execution_configuration (VAMExecutionConfiguration): Execution configuration for VAM.</p>"},{"location":"/home/jose/code/MainSequenceClientSide/mainsequence-sdk/docs/reference/virtualfundbuilder/config_handling/#mainsequence.virtualfundbuilder.config_handling.PricesConfiguration","title":"<code>PricesConfiguration</code>","text":"<p>               Bases: <code>VFBConfigBaseModel</code></p> <p>Configuration for price data handling in a portfolio.</p> <p>Attributes:     bar_frequency_id (str): The frequency of price bars.     upsample_frequency_id (str): Frequency to upsample intraday data to.     intraday_bar_interpolation_rule (str): Rule for interpolating missing intraday bars.     is_live (bool): Boolean flag indicating if the price feed is live.     markets_time_series List[MarketsTimeSeries]: The list of markets time series.</p>"},{"location":"/home/jose/code/MainSequenceClientSide/mainsequence-sdk/docs/reference/virtualfundbuilder/config_handling/#mainsequence.virtualfundbuilder.config_handling.TemplateFactory","title":"<code>TemplateFactory</code>","text":"<p>A factory for creating template-based objects, for example, market indices.</p>"},{"location":"/home/jose/code/MainSequenceClientSide/mainsequence-sdk/docs/reference/virtualfundbuilder/config_handling/#mainsequence.virtualfundbuilder.config_handling.TemplateFactory.create_market_index","title":"<code>create_market_index(index_name)</code>  <code>staticmethod</code>","text":"<p>Creates a market index portfolio object based on a predefined template configuration.</p> <p>Args:     index_name (str): The name of the index to create, which corresponds to a specific template configuration.</p> <p>Returns:     PortfolioStrategy: A PortfolioStrategy object configured according to the template.</p>"},{"location":"/home/jose/code/MainSequenceClientSide/mainsequence-sdk/docs/reference/virtualfundbuilder/config_handling/#mainsequence.virtualfundbuilder.config_handling.configuration_sanitizer","title":"<code>configuration_sanitizer(configuration)</code>","text":"<p>Verifies that a configuration has all the required attributes.</p> <p>If <code>auto_complete</code> is True, missing parts of the configuration will be auto-completed when possible.</p> <p>Args:     configuration (dict): The configuration dictionary to sanitize.     auto_complete (bool, optional): Whether to auto-complete missing parts. Defaults to False.</p> <p>Returns:     PortfolioConfiguration: The sanitized portfolio configuration.</p>"},{"location":"/home/jose/code/MainSequenceClientSide/mainsequence-sdk/docs/reference/virtualfundbuilder/config_handling/#mainsequence.virtualfundbuilder.config_handling.replace_none_with_python_none","title":"<code>replace_none_with_python_none(config)</code>","text":"<p>Recursively replace all string 'None' with Python None in the given dictionary and log the path where replacements occur.</p> <p>Args:     config (dict): The configuration dictionary.</p> <p>Returns:     dict: Updated dictionary with 'None' replaced by Python None.</p>"},{"location":"/home/jose/code/MainSequenceClientSide/mainsequence-sdk/docs/reference/virtualfundbuilder/enums/","title":"Enums","text":""},{"location":"/home/jose/code/MainSequenceClientSide/mainsequence-sdk/docs/reference/virtualfundbuilder/enums/#mainsequence.virtualfundbuilder.enums","title":"<code>mainsequence.virtualfundbuilder.enums</code>","text":""},{"location":"/home/jose/code/MainSequenceClientSide/mainsequence-sdk/docs/reference/virtualfundbuilder/models/","title":"Models","text":""},{"location":"/home/jose/code/MainSequenceClientSide/mainsequence-sdk/docs/reference/virtualfundbuilder/models/#mainsequence.virtualfundbuilder.models","title":"<code>mainsequence.virtualfundbuilder.models</code>","text":""},{"location":"/home/jose/code/MainSequenceClientSide/mainsequence-sdk/docs/reference/virtualfundbuilder/models/#mainsequence.virtualfundbuilder.models.AssetMixinOverwrite","title":"<code>AssetMixinOverwrite</code>","text":"<p>               Bases: <code>VFBConfigBaseModel</code></p> <p>The Asset for evaluating the portfolio.</p> <p>Attributes:     symbol (str): The symbol of the asset.     execution_venue_symbol (ExecutionVenueNames): The execution venue where the asset traded. Needs to match with asset universe.</p>"},{"location":"/home/jose/code/MainSequenceClientSide/mainsequence-sdk/docs/reference/virtualfundbuilder/models/#mainsequence.virtualfundbuilder.models.AssetsConfiguration","title":"<code>AssetsConfiguration</code>","text":"<p>               Bases: <code>VFBConfigBaseModel</code></p> <p>Configuration for assets included in a portfolio.</p> <p>Attributes:     assets_category_unique_id (str):         Unique Identifier of assets category     price_type (PriceTypeNames): Type of price used for backtesting.     prices_configuration (PricesConfiguration): Configuration for price data handling.</p>"},{"location":"/home/jose/code/MainSequenceClientSide/mainsequence-sdk/docs/reference/virtualfundbuilder/models/#mainsequence.virtualfundbuilder.models.BacktestingWeightsConfig","title":"<code>BacktestingWeightsConfig</code>","text":"<p>               Bases: <code>VFBConfigBaseModel</code></p> <p>Configuration for backtesting weights.</p> <p>Attributes:     rebalance_strategy_name (str): Strategy used for rebalancing.     rebalance_strategy_configuration (Dict): Placeholder dict for the rebalance strategy configuration.     signal_weights_name (str): Type of signal weights strategy.     signal_weights_configuration (Dict): Placeholder dict for the signal weights configuration.</p>"},{"location":"/home/jose/code/MainSequenceClientSide/mainsequence-sdk/docs/reference/virtualfundbuilder/models/#mainsequence.virtualfundbuilder.models.MarketsTimeSeries","title":"<code>MarketsTimeSeries</code>","text":"<p>               Bases: <code>VFBConfigBaseModel</code></p> <p>MarketsTimeSeries based on their unique id. Used as the data sources for the prices. Values include alpaca_1d_bars, binance_1d_bars etc.</p> <p>Attributes:     unique_identifier (str): Identfier of the MarketsTimeSeries.</p>"},{"location":"/home/jose/code/MainSequenceClientSide/mainsequence-sdk/docs/reference/virtualfundbuilder/models/#mainsequence.virtualfundbuilder.models.PortfolioBuildConfiguration","title":"<code>PortfolioBuildConfiguration</code>","text":"<p>               Bases: <code>VFBConfigBaseModel</code></p> <p>Main class for configuring and building a portfolio.</p> <p>This class defines the configuration parameters needed for building a portfolio, including asset configurations, backtesting weights, and execution parameters.</p> <p>Attributes:     assets_configuration (AssetsConfiguration): Configuration details for assets.     portfolio_prices_frequency (str): Frequency to upsample portoflio. Optional.     backtesting_weights_configuration (BacktestingWeightsConfig): Weights configuration used for backtesting.     execution_configuration (PortfolioExecutionConfiguration): Execution settings for the portfolio.     valuation_asset (AssetMixin): The Asset for evaluating the portfolio.</p>"},{"location":"/home/jose/code/MainSequenceClientSide/mainsequence-sdk/docs/reference/virtualfundbuilder/models/#mainsequence.virtualfundbuilder.models.PortfolioConfiguration","title":"<code>PortfolioConfiguration</code>","text":"<p>               Bases: <code>VFBConfigBaseModel</code></p> <pre><code>Configuration for a complete portfolio, including build configuration,\nTDAG updates, and VAM settings.\n\nThis class aggregates different configurations required for the\nmanagement and operation of a portfolio.\n</code></pre> <p>Attributes:     portfolio_build_configuration (PortfolioBuildConfiguration): Configuration for building the portfolio.     portfolio_markets_configuration (PortfolioMarketsConfig): VAM execution configuration.</p>"},{"location":"/home/jose/code/MainSequenceClientSide/mainsequence-sdk/docs/reference/virtualfundbuilder/models/#mainsequence.virtualfundbuilder.models.PortfolioExecutionConfiguration","title":"<code>PortfolioExecutionConfiguration</code>","text":"<p>               Bases: <code>VFBConfigBaseModel</code></p> <p>Configuration for portfolio execution.</p> <p>Attributes:     commission_fee (float): Commission fee percentage.</p>"},{"location":"/home/jose/code/MainSequenceClientSide/mainsequence-sdk/docs/reference/virtualfundbuilder/models/#mainsequence.virtualfundbuilder.models.PortfolioMarketsConfig","title":"<code>PortfolioMarketsConfig</code>","text":"<p>               Bases: <code>VFBConfigBaseModel</code></p> <p>Configuration for Virtual Asset Management (VAM) portfolio.</p> <p>Attributes:     portfolio_name (str): Name of the portfolio.     execution_configuration (VAMExecutionConfiguration): Execution configuration for VAM.</p>"},{"location":"/home/jose/code/MainSequenceClientSide/mainsequence-sdk/docs/reference/virtualfundbuilder/models/#mainsequence.virtualfundbuilder.models.PricesConfiguration","title":"<code>PricesConfiguration</code>","text":"<p>               Bases: <code>VFBConfigBaseModel</code></p> <p>Configuration for price data handling in a portfolio.</p> <p>Attributes:     bar_frequency_id (str): The frequency of price bars.     upsample_frequency_id (str): Frequency to upsample intraday data to.     intraday_bar_interpolation_rule (str): Rule for interpolating missing intraday bars.     is_live (bool): Boolean flag indicating if the price feed is live.     markets_time_series List[MarketsTimeSeries]: The list of markets time series.</p>"},{"location":"/home/jose/code/MainSequenceClientSide/mainsequence-sdk/docs/reference/virtualfundbuilder/notebook_handling/","title":"Notebook handling","text":""},{"location":"/home/jose/code/MainSequenceClientSide/mainsequence-sdk/docs/reference/virtualfundbuilder/notebook_handling/#mainsequence.virtualfundbuilder.notebook_handling","title":"<code>mainsequence.virtualfundbuilder.notebook_handling</code>","text":""},{"location":"/home/jose/code/MainSequenceClientSide/mainsequence-sdk/docs/reference/virtualfundbuilder/notebook_handling/#mainsequence.virtualfundbuilder.notebook_handling.convert_notebook_to_python_file","title":"<code>convert_notebook_to_python_file(notebook_path)</code>","text":"<p>Converts a Jupyter notebook to a Python file in a temporary directory.</p> <p>Args:     notebook_path (str or pathlib.Path): The path to the Jupyter notebook (.ipynb) file.</p> <p>Returns:     pathlib.Path: The path to the generated Python file in the temporary directory.</p>"},{"location":"/home/jose/code/MainSequenceClientSide/mainsequence-sdk/docs/reference/virtualfundbuilder/portfolio_interface/","title":"Portfolio interface","text":""},{"location":"/home/jose/code/MainSequenceClientSide/mainsequence-sdk/docs/reference/virtualfundbuilder/portfolio_interface/#mainsequence.virtualfundbuilder.portfolio_interface","title":"<code>mainsequence.virtualfundbuilder.portfolio_interface</code>","text":""},{"location":"/home/jose/code/MainSequenceClientSide/mainsequence-sdk/docs/reference/virtualfundbuilder/portfolio_interface/#mainsequence.virtualfundbuilder.portfolio_interface.PortfolioInterface","title":"<code>PortfolioInterface</code>","text":"<p>Manages the overall strategy of investing. It initializes the tree and runs it either within the scheduler or directly with a full tree update.</p>"},{"location":"/home/jose/code/MainSequenceClientSide/mainsequence-sdk/docs/reference/virtualfundbuilder/portfolio_interface/#mainsequence.virtualfundbuilder.portfolio_interface.PortfolioInterface.__init__","title":"<code>__init__(portfolio_config_template, build_purpose=CONSTANTS.PORTFOLIO_BUILD_FOR_BACKTEST, configuration_name=None)</code>","text":"<p>Initializes the portfolio strategy with the necessary configurations.</p>"},{"location":"/home/jose/code/MainSequenceClientSide/mainsequence-sdk/docs/reference/virtualfundbuilder/portfolio_interface/#mainsequence.virtualfundbuilder.portfolio_interface.PortfolioInterface.build_target_portfolio_in_backend","title":"<code>build_target_portfolio_in_backend(portfolio_tags=None)</code>","text":"<p>This method creates a portfolio in VAM with configm file settings.</p> <p>Returns:</p>"},{"location":"/home/jose/code/MainSequenceClientSide/mainsequence-sdk/docs/reference/virtualfundbuilder/portfolio_interface/#mainsequence.virtualfundbuilder.portfolio_interface.PortfolioInterface.delete_portfolio","title":"<code>delete_portfolio()</code>","text":"<p>Deletes the portfolio from vam :return:</p>"},{"location":"/home/jose/code/MainSequenceClientSide/mainsequence-sdk/docs/reference/virtualfundbuilder/portfolio_interface/#mainsequence.virtualfundbuilder.portfolio_interface.PortfolioInterface.delete_stored_configuration","title":"<code>delete_stored_configuration()</code>","text":"<p>Removes a saved configuration file from the configuration folder</p>"},{"location":"/home/jose/code/MainSequenceClientSide/mainsequence-sdk/docs/reference/virtualfundbuilder/portfolio_interface/#mainsequence.virtualfundbuilder.portfolio_interface.PortfolioInterface.list_configurations","title":"<code>list_configurations()</code>  <code>classmethod</code>","text":"<p>Lists all YAML configuration files found in the configuration_path.</p>"},{"location":"/home/jose/code/MainSequenceClientSide/mainsequence-sdk/docs/reference/virtualfundbuilder/portfolio_interface/#mainsequence.virtualfundbuilder.portfolio_interface.PortfolioInterface.store_configuration","title":"<code>store_configuration(configuration_name=None)</code>","text":"<p>Stores the current configuration as a YAML file under the configuration_name</p>"},{"location":"/home/jose/code/MainSequenceClientSide/mainsequence-sdk/docs/reference/virtualfundbuilder/time_series/","title":"Time series","text":""},{"location":"/home/jose/code/MainSequenceClientSide/mainsequence-sdk/docs/reference/virtualfundbuilder/time_series/#mainsequence.virtualfundbuilder.time_series","title":"<code>mainsequence.virtualfundbuilder.time_series</code>","text":""},{"location":"/home/jose/code/MainSequenceClientSide/mainsequence-sdk/docs/reference/virtualfundbuilder/time_series/#mainsequence.virtualfundbuilder.time_series.PortfolioStrategy","title":"<code>PortfolioStrategy</code>","text":"<p>               Bases: <code>TimeSerie</code></p> <p>Manages the rebalancing of asset weights within a portfolio over time, considering transaction fees and rebalancing strategies. Calculates portfolio values and returns while accounting for execution-specific fees.</p>"},{"location":"/home/jose/code/MainSequenceClientSide/mainsequence-sdk/docs/reference/virtualfundbuilder/time_series/#mainsequence.virtualfundbuilder.time_series.PortfolioStrategy.human_readable","title":"<code>human_readable</code>  <code>property</code>","text":"<p>Generates a human-readable name for the portfolio strategy.</p> <p>Returns:     str: Human-readable name.</p>"},{"location":"/home/jose/code/MainSequenceClientSide/mainsequence-sdk/docs/reference/virtualfundbuilder/time_series/#mainsequence.virtualfundbuilder.time_series.PortfolioStrategy.__init__","title":"<code>__init__(portfolio_build_configuration, *args, **kwargs)</code>","text":"<p>Initializes the PortfolioStrategy class with the necessary configurations.</p> <p>Args:     portfolio_build_configuration (PortfolioBuildConfiguration): Configuration for building the portfolio,         including assets, execution parameters, and backtesting weights.     is_live (bool): Flag indicating whether the strategy is running in live mode.</p>"},{"location":"/home/jose/code/MainSequenceClientSide/mainsequence-sdk/docs/reference/virtualfundbuilder/time_series/#mainsequence.virtualfundbuilder.time_series.PortfolioStrategy.get_portfolio_about_text","title":"<code>get_portfolio_about_text()</code>","text":"<p>Constructs the portfolio about text.</p> <p>Returns:     str: Portfolio description.</p>"},{"location":"/home/jose/code/MainSequenceClientSide/mainsequence-sdk/docs/reference/virtualfundbuilder/time_series/#mainsequence.virtualfundbuilder.time_series.PortfolioStrategy.update","title":"<code>update(update_statistics)</code>","text":"<p>Updates the portfolio weights based on the latest available data.</p> <p>Args:     latest_value (datetime): The timestamp of the latest available data.</p> <p>Returns:     pd.DataFrame: Updated portfolio values with and without fees and returns.</p>"},{"location":"/home/jose/code/MainSequenceClientSide/mainsequence-sdk/docs/reference/virtualfundbuilder/time_series/#mainsequence.virtualfundbuilder.time_series.translate_to_pandas_freq","title":"<code>translate_to_pandas_freq(custom_freq)</code>","text":"<p>Translate custom datetime frequency strings to Pandas frequency strings.</p> <p>Args:     custom_freq (str): Custom frequency string (e.g., '1d', '1m', '1mo').</p> <p>Returns:     str: Pandas frequency string (e.g., 'D', 'T', 'M').</p>"},{"location":"/home/jose/code/MainSequenceClientSide/mainsequence-sdk/docs/reference/virtualfundbuilder/utils/","title":"Utils","text":""},{"location":"/home/jose/code/MainSequenceClientSide/mainsequence-sdk/docs/reference/virtualfundbuilder/utils/#mainsequence.virtualfundbuilder.utils","title":"<code>mainsequence.virtualfundbuilder.utils</code>","text":""},{"location":"/home/jose/code/MainSequenceClientSide/mainsequence-sdk/docs/reference/virtualfundbuilder/utils/#mainsequence.virtualfundbuilder.utils.build_markdown","title":"<code>build_markdown(root_class, persist=True, elements_to_exclude=None, children_to_exclude=None)</code>","text":"<p>Builds standards portfolio configuration documentation Returns:</p>"},{"location":"/home/jose/code/MainSequenceClientSide/mainsequence-sdk/docs/reference/virtualfundbuilder/utils/#mainsequence.virtualfundbuilder.utils.build_rolling_regression_from_df","title":"<code>build_rolling_regression_from_df(x, y, rolling_window, column_names, threads=5)</code>","text":"<p>Builds rolling regressions for multiple variables in parallel using a specified rolling window.</p> <p>Args:     x (NDArray): An array of independent variables.     y (NDArray): An array of dependent variables.     rolling_window (int): The size of the rolling window for each regression.     column_names (list): Names of the dependent variables, used for labeling the output.     threads (int): Number of threads to use for parallel processing.</p> <p>Returns:     pd.DataFrame: A DataFrame containing the regression results for all variables.</p>"},{"location":"/home/jose/code/MainSequenceClientSide/mainsequence-sdk/docs/reference/virtualfundbuilder/utils/#mainsequence.virtualfundbuilder.utils.convert_to_binance_frequency","title":"<code>convert_to_binance_frequency(freq)</code>","text":"<p>Converts a generic frequency format to a format compatible with Binance API requirements.</p> <p>Args:     freq (str): The generic frequency format (e.g., '1m', '1h').</p> <p>Returns:     str: A frequency string adapted for Binance API (e.g., '1m', '1h').</p>"},{"location":"/home/jose/code/MainSequenceClientSide/mainsequence-sdk/docs/reference/virtualfundbuilder/utils/#mainsequence.virtualfundbuilder.utils.default_config_to_dict","title":"<code>default_config_to_dict(default_config)</code>","text":"<p>Convert the default configuration into a Python dictionary.</p> <p>Args:     default_config (dict): Default configuration from the VFB tool.</p> <p>Returns:     dict: Processed configuration dictionary.</p>"},{"location":"/home/jose/code/MainSequenceClientSide/mainsequence-sdk/docs/reference/virtualfundbuilder/utils/#mainsequence.virtualfundbuilder.utils.do_single_regression","title":"<code>do_single_regression(xx, XTX_inv_list, rolling_window, col_name, tmp_y, XTX_inv_diag)</code>","text":"<p>Performs a single regression analysis on a sliding window of data points for a specific column.</p> <p>Args:     xx (NDArray): An array of independent variable data with a sliding window applied.     XTX_inv_list (list): A list of precomputed inverse matrices of X.T @ X for each window.     rolling_window (int): The number of observations per window.     col_name (str): The name of the column being analyzed, used for labeling the output.     tmp_y (NDArray): The dependent variable data.     XTX_inv_diag (list): Diagonals of the precomputed inverse matrices, used for standard error calculation.</p> <p>Returns:     pd.DataFrame: A DataFrame containing the regression results with coefficients, R-squared, and t-statistics.</p>"},{"location":"/home/jose/code/MainSequenceClientSide/mainsequence-sdk/docs/reference/virtualfundbuilder/utils/#mainsequence.virtualfundbuilder.utils.filter_assets","title":"<code>filter_assets(df, asset_list)</code>","text":"<p>Filters a DataFrame to include only rows that have asset symbols contained in a given asset list.</p>"},{"location":"/home/jose/code/MainSequenceClientSide/mainsequence-sdk/docs/reference/virtualfundbuilder/utils/#mainsequence.virtualfundbuilder.utils.get_last_query_times_per_asset","title":"<code>get_last_query_times_per_asset(latest_value, metadata, asset_list, max_lookback_time, current_time, query_frequency)</code>","text":"<p>Determines the last query times for each asset based on metadata, a specified lookback limit, and a query frequency.</p> <p>Args:     latest_value (datetime|None): Timestamp of the last value in the database for each asset.     metadata (dict): Metadata containing previous query information for each coin.     asset_list (List[Asset]): List of asset objects to process.     max_lookback_time (datetime): Maximum historical lookback time allowed for the node.     current_time (datetime): Current time to consider for the calculations.     query_frequency (str): Query frequency as a pandas-parseable string to determine if new data needs fetching.</p> <p>Returns:     Dict[str, Optional[float]]: A dictionary mapping asset IDs to their respective last query times expressed in UNIX timestamp.</p>"},{"location":"/home/jose/code/MainSequenceClientSide/mainsequence-sdk/docs/reference/virtualfundbuilder/utils/#mainsequence.virtualfundbuilder.utils.object_signature_to_markdown","title":"<code>object_signature_to_markdown(root_dict, level=1, elements_to_exclude=None, children_to_exclude=None)</code>","text":"<p>Convert a nested dictionary structure into a markdown formatted string.</p> <p>Args: - root_dict (dict): The nested dictionary to convert. - level (int): The current markdown header level.</p> <p>Returns: - str: The markdown formatted string.</p>"},{"location":"/home/jose/code/MainSequenceClientSide/mainsequence-sdk/docs/reference/virtualfundbuilder/utils/#mainsequence.virtualfundbuilder.utils.object_signature_to_yaml","title":"<code>object_signature_to_yaml(default_config)</code>","text":"<p>Convert the default configuration dictionary to a YAML string.</p> <p>Args:     default_config (dict): Default configuration from the VFB tool.</p> <p>Returns:     str: YAML formatted string of the configuration.</p>"},{"location":"/home/jose/code/MainSequenceClientSide/mainsequence-sdk/docs/reference/virtualfundbuilder/utils/#mainsequence.virtualfundbuilder.utils.reindex_df","title":"<code>reindex_df(df, start_time, end_time, freq)</code>","text":"<p>Aligns two DataFrames on a new index based on a specified frequency, filling missing entries with the last known values.</p> <p>Args:     df (pd.DataFrame): Reference DataFrame used to determine the new index range.     start_time (datetime): start of index     end_time (datetime): end of index     freq (str): Frequency string (e.g., '1T' for one minute) to define the interval of the new index.</p> <p>Returns:     pd.DataFrame: The df_to_align DataFrame reindexed to match the new timeline and filled with forward filled values.</p>"},{"location":"/home/jose/code/MainSequenceClientSide/mainsequence-sdk/docs/reference/virtualfundbuilder/contrib/apps/generate_report/","title":"Generate report","text":""},{"location":"/home/jose/code/MainSequenceClientSide/mainsequence-sdk/docs/reference/virtualfundbuilder/contrib/apps/generate_report/#mainsequence.virtualfundbuilder.contrib.apps.generate_report","title":"<code>mainsequence.virtualfundbuilder.contrib.apps.generate_report</code>","text":""},{"location":"/home/jose/code/MainSequenceClientSide/mainsequence-sdk/docs/reference/virtualfundbuilder/contrib/apps/generate_report/#mainsequence.virtualfundbuilder.contrib.apps.generate_report.ReportApp","title":"<code>ReportApp</code>","text":"<p>               Bases: <code>BaseApp</code></p> <p>Minimal example of a 'ReportApp' that can: 1) Generate dummy data and create charts (line + heatmap). 2) Embed those charts into an HTML template. 3) Optionally export the HTML to PDF using WeasyPrint.</p>"},{"location":"/home/jose/code/MainSequenceClientSide/mainsequence-sdk/docs/reference/virtualfundbuilder/contrib/apps/generate_report/#mainsequence.virtualfundbuilder.contrib.apps.generate_report.ReportApp.run","title":"<code>run()</code>","text":"<p>Generates an HTML report (and optional PDF) in a minimal, self-contained way.</p>"},{"location":"/home/jose/code/MainSequenceClientSide/mainsequence-sdk/docs/reference/virtualfundbuilder/contrib/apps/generate_report/#mainsequence.virtualfundbuilder.contrib.apps.generate_report.ReportConfig","title":"<code>ReportConfig</code>","text":"<p>               Bases: <code>BaseModel</code></p> <p>Pydantic model defining the parameters for report generation.</p>"},{"location":"/home/jose/code/MainSequenceClientSide/mainsequence-sdk/docs/reference/virtualfundbuilder/contrib/apps/generate_report/#mainsequence.virtualfundbuilder.contrib.apps.generate_report.example_data","title":"<code>example_data(assets)</code>","text":"<p>Fetch real data from the 'api_ts.get_df_between_dates()' call, then:   1) Build a time-series chart of 'Revenue' vs. time for each asset (ticker).   2) Build a correlation heatmap of 'Revenue' vs. 'EPS' for the latest time period.   3) Return both figures as Base64-encoded PNGs.</p>"},{"location":"/home/jose/code/MainSequenceClientSide/mainsequence-sdk/docs/reference/virtualfundbuilder/contrib/apps/news_app/","title":"News app","text":""},{"location":"/home/jose/code/MainSequenceClientSide/mainsequence-sdk/docs/reference/virtualfundbuilder/contrib/apps/news_app/#mainsequence.virtualfundbuilder.contrib.apps.news_app","title":"<code>mainsequence.virtualfundbuilder.contrib.apps.news_app</code>","text":""},{"location":"/home/jose/code/MainSequenceClientSide/mainsequence-sdk/docs/reference/virtualfundbuilder/contrib/apps/news_app/#mainsequence.virtualfundbuilder.contrib.apps.news_app.SentimentReport","title":"<code>SentimentReport</code>","text":"<p>               Bases: <code>BaseApp</code></p> <p>Generates an HTML report summarizing news sentiment and headlines for a list of stock tickers using data from Polygon.io. Additionally, fetches the first 100 words of each article (if possible) and generates a single combined summary displayed below the combined chart.</p>"},{"location":"/home/jose/code/MainSequenceClientSide/mainsequence-sdk/docs/reference/virtualfundbuilder/contrib/apps/news_app/#mainsequence.virtualfundbuilder.contrib.apps.news_app.SentimentReport.run","title":"<code>run()</code>","text":"<p>Orchestrates the report generation process:   1. Fetch data,   2. Create plots,   3. Attempt to retrieve article text (first 100 words) for all articles,   4. Generate a single combined summary from those snippets,   5. Render HTML,   6. Upload artifact.</p>"},{"location":"/home/jose/code/MainSequenceClientSide/mainsequence-sdk/docs/reference/virtualfundbuilder/contrib/apps/news_app/#mainsequence.virtualfundbuilder.contrib.apps.news_app.SentimentReportConfig","title":"<code>SentimentReportConfig</code>","text":"<p>               Bases: <code>BaseModel</code></p> <p>Pydantic model defining parameters for the Sentiment Report.</p>"},{"location":"/home/jose/code/MainSequenceClientSide/mainsequence-sdk/docs/reference/virtualfundbuilder/contrib/prices/time_series/","title":"Time series","text":""},{"location":"/home/jose/code/MainSequenceClientSide/mainsequence-sdk/docs/reference/virtualfundbuilder/contrib/prices/time_series/#mainsequence.virtualfundbuilder.contrib.prices.time_series","title":"<code>mainsequence.virtualfundbuilder.contrib.prices.time_series</code>","text":""},{"location":"/home/jose/code/MainSequenceClientSide/mainsequence-sdk/docs/reference/virtualfundbuilder/contrib/prices/time_series/#mainsequence.virtualfundbuilder.contrib.prices.time_series.InterpolatedPrices","title":"<code>InterpolatedPrices</code>","text":"<p>               Bases: <code>TimeSerie</code></p> <p>Handles interpolated prices for assets.</p>"},{"location":"/home/jose/code/MainSequenceClientSide/mainsequence-sdk/docs/reference/virtualfundbuilder/contrib/prices/time_series/#mainsequence.virtualfundbuilder.contrib.prices.time_series.InterpolatedPrices.human_readable","title":"<code>human_readable: str</code>  <code>property</code>","text":"<p>Returns a human-readable string representation of the object.</p>"},{"location":"/home/jose/code/MainSequenceClientSide/mainsequence-sdk/docs/reference/virtualfundbuilder/contrib/prices/time_series/#mainsequence.virtualfundbuilder.contrib.prices.time_series.InterpolatedPrices.__init__","title":"<code>__init__(asset_category_unique_id, bar_frequency_id, intraday_bar_interpolation_rule, markets_time_series_unique_id_list, upsample_frequency_id=None, asset_filter=None, local_kwargs_to_ignore=['asset_category_unique_id'], *args, **kwargs)</code>","text":"<p>Initializes the InterpolatedPrices object.</p>"},{"location":"/home/jose/code/MainSequenceClientSide/mainsequence-sdk/docs/reference/virtualfundbuilder/contrib/prices/time_series/#mainsequence.virtualfundbuilder.contrib.prices.time_series.InterpolatedPrices.get_upsampled_data","title":"<code>get_upsampled_data(update_statistics)</code>","text":"<p>Main method to get upsampled data for prices.</p>"},{"location":"/home/jose/code/MainSequenceClientSide/mainsequence-sdk/docs/reference/virtualfundbuilder/contrib/prices/time_series/#mainsequence.virtualfundbuilder.contrib.prices.time_series.InterpolatedPrices.run_after_post_init_routines","title":"<code>run_after_post_init_routines()</code>","text":"<p>Use post init routines to configure the time series</p>"},{"location":"/home/jose/code/MainSequenceClientSide/mainsequence-sdk/docs/reference/virtualfundbuilder/contrib/prices/time_series/#mainsequence.virtualfundbuilder.contrib.prices.time_series.InterpolatedPrices.update","title":"<code>update(update_statistics)</code>","text":"<p>Updates the series from the source based on the latest value.</p>"},{"location":"/home/jose/code/MainSequenceClientSide/mainsequence-sdk/docs/reference/virtualfundbuilder/contrib/prices/time_series/#mainsequence.virtualfundbuilder.contrib.prices.time_series.InterpolatedPricesLive","title":"<code>InterpolatedPricesLive</code>","text":"<p>Handles interpolated prices for assets.</p>"},{"location":"/home/jose/code/MainSequenceClientSide/mainsequence-sdk/docs/reference/virtualfundbuilder/contrib/prices/time_series/#mainsequence.virtualfundbuilder.contrib.prices.time_series.InterpolatedPricesLive.__init__","title":"<code>__init__(asset_list, bar_frequency_id, intraday_bar_interpolation_rule, upsample_frequency_id=None, local_kwargs_to_ignore=['asset_list'], *args, **kwargs)</code>","text":"<p>Initializes the InterpolatedPricesLive object.</p>"},{"location":"/home/jose/code/MainSequenceClientSide/mainsequence-sdk/docs/reference/virtualfundbuilder/contrib/prices/time_series/#mainsequence.virtualfundbuilder.contrib.prices.time_series.InterpolatedPricesLive.get_earliest_value_for_initial_update","title":"<code>get_earliest_value_for_initial_update()</code>","text":"<p>Get the earliest value for the initial update.</p>"},{"location":"/home/jose/code/MainSequenceClientSide/mainsequence-sdk/docs/reference/virtualfundbuilder/contrib/prices/time_series/#mainsequence.virtualfundbuilder.contrib.prices.time_series.InterpolatedPricesLive.update","title":"<code>update(update_statistics)</code>","text":"<p>Updates the series from the source based on the latest value.</p>"},{"location":"/home/jose/code/MainSequenceClientSide/mainsequence-sdk/docs/reference/virtualfundbuilder/contrib/prices/time_series/#mainsequence.virtualfundbuilder.contrib.prices.time_series.UpsampleAndInterpolation","title":"<code>UpsampleAndInterpolation</code>","text":"<p>Handles upsampling and interpolation of bar data.</p>"},{"location":"/home/jose/code/MainSequenceClientSide/mainsequence-sdk/docs/reference/virtualfundbuilder/contrib/prices/time_series/#mainsequence.virtualfundbuilder.contrib.prices.time_series.UpsampleAndInterpolation.get_interpolated_upsampled_bars","title":"<code>get_interpolated_upsampled_bars(calendar, tmp_df, last_observation=None)</code>","text":"<p>Gets interpolated and upsampled bars based on the given parameters. First interpolates the data to fill any gaps, then upsamples it to the desired frequency.</p> <p>Args:     calendar (str): Trading calendar for interpolation and upsampling.     tmp_df (pd.DataFrame): Dataframe containing the bars to be processed.     last_observation (Union[None, pd.Series], optional): Last observed data to fill gaps.</p> <p>Returns:     pd.DataFrame: Interpolated and upsampled bars dataframe.</p>"},{"location":"/home/jose/code/MainSequenceClientSide/mainsequence-sdk/docs/reference/virtualfundbuilder/contrib/prices/time_series/#mainsequence.virtualfundbuilder.contrib.prices.time_series.UpsampleAndInterpolation.upsample_bars","title":"<code>upsample_bars(bars_df, upsample_frequency_obs, upsample_frequency_td, calendar, open_to_close_time_delta, is_portfolio=False)</code>  <code>staticmethod</code>","text":"<p>Upsamples the bars dataframe based on the given parameters. For example, it can convert 5-minute bars to 1-minute bars. Note that this method works on iloc as the underlying data should be already interpolated so should be completed</p> <p>Args:     bars_df (pd.DataFrame): The bars data to be upsampled.     upsample_frequency_obs (int): Frequency for upsampling.     upsample_frequency_td (object): Time delta for upsampling.     calendar (str): Trading calendar to account for trading hours.     open_to_close_time_delta (datetime.timedelta): Time delta between open and close.     is_portfolio (bool): Whether the data is for a portfolio or a single asset.</p> <p>Returns:     pd.DataFrame: The upsampled bars dataframe.</p>"},{"location":"/home/jose/code/MainSequenceClientSide/mainsequence-sdk/docs/reference/virtualfundbuilder/contrib/prices/time_series/#mainsequence.virtualfundbuilder.contrib.prices.time_series.get_interpolated_prices_timeseries","title":"<code>get_interpolated_prices_timeseries(assets_configuration)</code>","text":"<p>Creates a Wrapper Timeseries for an asset configuration.</p>"},{"location":"/home/jose/code/MainSequenceClientSide/mainsequence-sdk/docs/reference/virtualfundbuilder/contrib/prices/time_series/#mainsequence.virtualfundbuilder.contrib.prices.time_series.get_time_serie_from_markets_unique_id","title":"<code>get_time_serie_from_markets_unique_id(market_time_serie_unique_identifier)</code>","text":"<p>Returns the appropriate bar time series based on the asset list and source.</p>"},{"location":"/home/jose/code/MainSequenceClientSide/mainsequence-sdk/docs/reference/virtualfundbuilder/contrib/prices/time_series/#mainsequence.virtualfundbuilder.contrib.prices.time_series.interpolate_intraday_bars","title":"<code>interpolate_intraday_bars(bars_df, interpolation_rule, bars_frequency_min, calendar, last_observation=None)</code>","text":"<p>Interpolates intraday bars based on the given parameters. Fills in missing data points in intraday bar data in case of gaps.</p>"},{"location":"/home/jose/code/MainSequenceClientSide/mainsequence-sdk/docs/reference/virtualfundbuilder/contrib/prices/utils/","title":"Utils","text":""},{"location":"/home/jose/code/MainSequenceClientSide/mainsequence-sdk/docs/reference/virtualfundbuilder/contrib/prices/utils/#mainsequence.virtualfundbuilder.contrib.prices.utils","title":"<code>mainsequence.virtualfundbuilder.contrib.prices.utils</code>","text":""},{"location":"/home/jose/code/MainSequenceClientSide/mainsequence-sdk/docs/reference/virtualfundbuilder/contrib/rebalance_strategies/rebalance_strategies/","title":"Rebalance strategies","text":""},{"location":"/home/jose/code/MainSequenceClientSide/mainsequence-sdk/docs/reference/virtualfundbuilder/contrib/rebalance_strategies/rebalance_strategies/#mainsequence.virtualfundbuilder.contrib.rebalance_strategies.rebalance_strategies","title":"<code>mainsequence.virtualfundbuilder.contrib.rebalance_strategies.rebalance_strategies</code>","text":""},{"location":"/home/jose/code/MainSequenceClientSide/mainsequence-sdk/docs/reference/virtualfundbuilder/contrib/rebalance_strategies/rebalance_strategies/#mainsequence.virtualfundbuilder.contrib.rebalance_strategies.rebalance_strategies.ImmediateSignal","title":"<code>ImmediateSignal</code>","text":"<p>               Bases: <code>RebalanceStrategyBase</code></p> <p>This rebalance strategy 'immediately' rebalances the weights. This is equivalent to just using the signal weights.</p>"},{"location":"/home/jose/code/MainSequenceClientSide/mainsequence-sdk/docs/reference/virtualfundbuilder/contrib/rebalance_strategies/rebalance_strategies/#mainsequence.virtualfundbuilder.contrib.rebalance_strategies.rebalance_strategies.ImmediateSignal.__init__","title":"<code>__init__(*args, **kwargs)</code>","text":"<p>Initialize the immediate rebalance strategy.</p>"},{"location":"/home/jose/code/MainSequenceClientSide/mainsequence-sdk/docs/reference/virtualfundbuilder/contrib/rebalance_strategies/rebalance_strategies/#mainsequence.virtualfundbuilder.contrib.rebalance_strategies.rebalance_strategies.TimeWeighted","title":"<code>TimeWeighted</code>","text":"<p>               Bases: <code>RebalanceStrategyBase</code></p>"},{"location":"/home/jose/code/MainSequenceClientSide/mainsequence-sdk/docs/reference/virtualfundbuilder/contrib/rebalance_strategies/rebalance_strategies/#mainsequence.virtualfundbuilder.contrib.rebalance_strategies.rebalance_strategies.TimeWeighted.__init__","title":"<code>__init__(rebalance_start='9:00', rebalance_end='23:00', rebalance_frequency_strategy=RebalanceFrequencyStrategyName.DAILY, *args, **kwargs)</code>","text":"<p>Initialize the time weighted rebalance strategy.</p> <p>Attributes:     rebalance_start (str): Start time for rebalancing, in \"hh:mm\" format.     rebalance_end (str): End time for rebalancing, in \"hh:mm\" format.     rebalance_frequency_strategy (RebalanceFrequencyStrategyName): Rebalance frequency.     max_percent_volume_in_bar (float): Maximum percentage of volume to trade in a bar.     total_notional (int): Initial notional invested in the strategy.</p>"},{"location":"/home/jose/code/MainSequenceClientSide/mainsequence-sdk/docs/reference/virtualfundbuilder/contrib/rebalance_strategies/rebalance_strategies/#mainsequence.virtualfundbuilder.contrib.rebalance_strategies.rebalance_strategies.TimeWeighted.apply_rebalance_logic","title":"<code>apply_rebalance_logic(last_rebalance_weights, start_date, end_date, signal_weights, prices_df, price_type)</code>","text":"<p>Rebalance weights are set at start_time of rebalancing</p> <p>Parameters:</p> Name Type Description Default <code>signal_weights</code> <code>DataFrame</code> required <code>rebalance_dates</code> required"},{"location":"/home/jose/code/MainSequenceClientSide/mainsequence-sdk/docs/reference/virtualfundbuilder/contrib/rebalance_strategies/rebalance_strategies/#mainsequence.virtualfundbuilder.contrib.rebalance_strategies.rebalance_strategies.VolumeParticipation","title":"<code>VolumeParticipation</code>","text":"<p>               Bases: <code>RebalanceStrategyBase</code></p> <p>This rebalance strategy implies volume participation with no market impact. i.e. that the execution price will be vwap and it will never execute more than max_percent_volume_in_bar</p>"},{"location":"/home/jose/code/MainSequenceClientSide/mainsequence-sdk/docs/reference/virtualfundbuilder/contrib/rebalance_strategies/rebalance_strategies/#mainsequence.virtualfundbuilder.contrib.rebalance_strategies.rebalance_strategies.VolumeParticipation.__init__","title":"<code>__init__(rebalance_start='9:00', rebalance_end='23:00', rebalance_frequency_strategy=RebalanceFrequencyStrategyName.DAILY, max_percent_volume_in_bar=0.01, total_notional=50000000, *args, **kwargs)</code>","text":"<p>Initializes the VolumeParticipation strategy.</p> <p>Attributes:     rebalance_start (str): Start time for rebalancing, in \"hh:mm\" format.     rebalance_end (str): End time for rebalancing, in \"hh:mm\" format.     rebalance_frequency_strategy (RebalanceFrequencyStrategyName): Rebalance frequency.     max_percent_volume_in_bar (float): Maximum percentage of volume to trade in a bar.     total_notional (int): Initial notional invested in the strategy.</p>"},{"location":"/home/jose/code/MainSequenceClientSide/mainsequence-sdk/docs/reference/virtualfundbuilder/contrib/rebalance_strategies/rebalance_strategies/#mainsequence.virtualfundbuilder.contrib.rebalance_strategies.rebalance_strategies.VolumeParticipation.apply_rebalance_logic","title":"<code>apply_rebalance_logic(last_rebalance_weights, start_date, end_date, signal_weights, prices_df, price_type)</code>","text":"<p>Parameters:</p> Name Type Description Default <code>signal_weights</code> <code>DataFrame</code> required <code>rebalance_dates</code> required"},{"location":"/home/jose/code/MainSequenceClientSide/mainsequence-sdk/docs/reference/virtualfundbuilder/contrib/templates/asset_groups/","title":"Asset groups","text":""},{"location":"/home/jose/code/MainSequenceClientSide/mainsequence-sdk/docs/reference/virtualfundbuilder/contrib/templates/asset_groups/#mainsequence.virtualfundbuilder.contrib.templates.asset_groups","title":"<code>mainsequence.virtualfundbuilder.contrib.templates.asset_groups</code>","text":""},{"location":"/home/jose/code/MainSequenceClientSide/mainsequence-sdk/docs/reference/virtualfundbuilder/contrib/time_series/intraday_trend/","title":"Intraday trend","text":""},{"location":"/home/jose/code/MainSequenceClientSide/mainsequence-sdk/docs/reference/virtualfundbuilder/contrib/time_series/intraday_trend/#mainsequence.virtualfundbuilder.contrib.time_series.intraday_trend","title":"<code>mainsequence.virtualfundbuilder.contrib.time_series.intraday_trend</code>","text":""},{"location":"/home/jose/code/MainSequenceClientSide/mainsequence-sdk/docs/reference/virtualfundbuilder/contrib/time_series/intraday_trend/#mainsequence.virtualfundbuilder.contrib.time_series.intraday_trend.IntradayTrend","title":"<code>IntradayTrend</code>","text":"<p>               Bases: <code>WeightsBase</code>, <code>TimeSerie</code></p>"},{"location":"/home/jose/code/MainSequenceClientSide/mainsequence-sdk/docs/reference/virtualfundbuilder/contrib/time_series/intraday_trend/#mainsequence.virtualfundbuilder.contrib.time_series.intraday_trend.IntradayTrend.__init__","title":"<code>__init__(calendar, source_frequency='1d', *args, **kwargs)</code>","text":"<p>Signal Weights</p> <p>Arguments     source_frequency (str): Frequency of market cap source</p>"},{"location":"/home/jose/code/MainSequenceClientSide/mainsequence-sdk/docs/reference/virtualfundbuilder/contrib/time_series/intraday_trend/#mainsequence.virtualfundbuilder.contrib.time_series.intraday_trend.IntradayTrend.update","title":"<code>update(latest_value, params_for_tree_run=None, *args, **kwargs)</code>","text":"<p>Updates the weights considering rebalance periods and execution frequency.</p> <p>Args:     latest_value Union[datetime, None]: The timestamp of the latest available data.</p>"},{"location":"/home/jose/code/MainSequenceClientSide/mainsequence-sdk/docs/reference/virtualfundbuilder/contrib/time_series/market_cap/","title":"Market cap","text":""},{"location":"/home/jose/code/MainSequenceClientSide/mainsequence-sdk/docs/reference/virtualfundbuilder/contrib/time_series/market_cap/#mainsequence.virtualfundbuilder.contrib.time_series.market_cap","title":"<code>mainsequence.virtualfundbuilder.contrib.time_series.market_cap</code>","text":""},{"location":"/home/jose/code/MainSequenceClientSide/mainsequence-sdk/docs/reference/virtualfundbuilder/contrib/time_series/market_cap/#mainsequence.virtualfundbuilder.contrib.time_series.market_cap.FixedWeights","title":"<code>FixedWeights</code>","text":"<p>               Bases: <code>WeightsBase</code>, <code>TimeSerie</code></p>"},{"location":"/home/jose/code/MainSequenceClientSide/mainsequence-sdk/docs/reference/virtualfundbuilder/contrib/time_series/market_cap/#mainsequence.virtualfundbuilder.contrib.time_series.market_cap.FixedWeights.__init__","title":"<code>__init__(asset_symbol_weights, *args, **kwargs)</code>","text":"<p>Args:     asset_symbol_weights (List[SymbolWeight]): List of SymbolWeights that map asset symbols to weights</p>"},{"location":"/home/jose/code/MainSequenceClientSide/mainsequence-sdk/docs/reference/virtualfundbuilder/contrib/time_series/market_cap/#mainsequence.virtualfundbuilder.contrib.time_series.market_cap.MarketCap","title":"<code>MarketCap</code>","text":"<p>               Bases: <code>WeightsBase</code>, <code>TimeSerie</code></p>"},{"location":"/home/jose/code/MainSequenceClientSide/mainsequence-sdk/docs/reference/virtualfundbuilder/contrib/time_series/market_cap/#mainsequence.virtualfundbuilder.contrib.time_series.market_cap.MarketCap.__init__","title":"<code>__init__(historical_market_cap_ts_unique_identifier, minimum_atvr_ratio=0.1, rolling_atvr_volume_windows=[60, 360], frequency_trading_percent=0.9, source_frequency='1d', min_number_of_assets=3, volatility_control_configuration=None, num_top_assets=None, *args, **kwargs)</code>","text":"<p>Signal Weights using weighting by Market Capitalization or Equal Weights</p> <p>Args:     source_frequency (str): Frequency of market cap source.     num_top_assets (Optional[int]): Number of largest assets by market cap to use for signals. Leave empty to include all assets.</p>"},{"location":"/home/jose/code/MainSequenceClientSide/mainsequence-sdk/docs/reference/virtualfundbuilder/contrib/time_series/market_cap/#mainsequence.virtualfundbuilder.contrib.time_series.market_cap.MarketCap.update","title":"<code>update(update_statistics)</code>","text":"<p>Args:     latest_value (Union[datetime, None]): The timestamp of the most recent data point.</p> <p>Returns:     DataFrame: A DataFrame containing updated signal weights, indexed by time and asset symbol.</p>"},{"location":"/home/jose/code/MainSequenceClientSide/mainsequence-sdk/docs/reference/virtualfundbuilder/contrib/time_series/mock_signal/","title":"Mock signal","text":""},{"location":"/home/jose/code/MainSequenceClientSide/mainsequence-sdk/docs/reference/virtualfundbuilder/contrib/time_series/mock_signal/#mainsequence.virtualfundbuilder.contrib.time_series.mock_signal","title":"<code>mainsequence.virtualfundbuilder.contrib.time_series.mock_signal</code>","text":""},{"location":"/home/jose/code/MainSequenceClientSide/mainsequence-sdk/docs/reference/virtualfundbuilder/contrib/time_series/mock_signal/#mainsequence.virtualfundbuilder.contrib.time_series.mock_signal.MockSignal","title":"<code>MockSignal</code>","text":"<p>               Bases: <code>WeightsBase</code>, <code>TimeSerie</code></p> <p>Mock Signal to test strategies. Creates a signal with long/short of ETH and BTC in frequency.</p>"},{"location":"/home/jose/code/MainSequenceClientSide/mainsequence-sdk/docs/reference/virtualfundbuilder/contrib/time_series/mock_signal/#mainsequence.virtualfundbuilder.contrib.time_series.mock_signal.MockSignal.update","title":"<code>update(latest_value, *args, **kwargs)</code>","text":"<p>Args:     latest_value (Union[datetime, None]): The timestamp of the most recent data point.</p> <p>Returns:     DataFrame: A DataFrame containing updated signal weights, indexed by time and asset symbol.</p>"},{"location":"/home/jose/code/MainSequenceClientSide/mainsequence-sdk/docs/reference/virtualfundbuilder/contrib/time_series/portfolio_replicator/","title":"Portfolio replicator","text":""},{"location":"/home/jose/code/MainSequenceClientSide/mainsequence-sdk/docs/reference/virtualfundbuilder/contrib/time_series/portfolio_replicator/#mainsequence.virtualfundbuilder.contrib.time_series.portfolio_replicator","title":"<code>mainsequence.virtualfundbuilder.contrib.time_series.portfolio_replicator</code>","text":""},{"location":"/home/jose/code/MainSequenceClientSide/mainsequence-sdk/docs/reference/virtualfundbuilder/contrib/time_series/portfolio_replicator/#mainsequence.virtualfundbuilder.contrib.time_series.portfolio_replicator.ETFReplicator","title":"<code>ETFReplicator</code>","text":"<p>               Bases: <code>WeightsBase</code>, <code>TimeSerie</code></p>"},{"location":"/home/jose/code/MainSequenceClientSide/mainsequence-sdk/docs/reference/virtualfundbuilder/contrib/time_series/portfolio_replicator/#mainsequence.virtualfundbuilder.contrib.time_series.portfolio_replicator.ETFReplicator.__init__","title":"<code>__init__(symbol_to_replicate, tracking_strategy_configuration, in_window=60, tracking_strategy=TrackingStrategy.LASSO, *args, **kwargs)</code>","text":"<p>Initialize the ETFReplicator.</p> <p>Args:     symbol_to_replicate (str): Symbol of the asset to replicate. Must be included in the signals asset universe.     tracking_strategy_configuration (TrackingStrategyConfiguration): Configuration parameters for the tracking strategy.     in_window (int, optional): The size of the rolling window for regression. Defaults to 60.     tracking_strategy (TrackingStrategy, optional): The regression strategy to use for tracking. Defaults to TrackingStrategy.LASSO.     args: Variable length argument list.     *kwargs: Arbitrary keyword arguments.</p>"},{"location":"/home/jose/code/MainSequenceClientSide/mainsequence-sdk/docs/reference/virtualfundbuilder/contrib/time_series/portfolio_replicator/#mainsequence.virtualfundbuilder.contrib.time_series.portfolio_replicator.rolling_elastic_net","title":"<code>rolling_elastic_net(y, X, window, alpha=1.0, l1_ratio=0.5)</code>","text":"<p>Perform rolling Elastic Net regression and return the coefficients.</p> <p>Parameters:     y (pd.Series): Target variable.     X (pd.DataFrame): Feature variables.     window (int): Size of the rolling window.     alpha (float, optional): Regularization strength. Defaults to 1.0.     l1_ratio (float, optional): The ElasticNet mixing parameter. Defaults to 0.5.</p> <p>Returns:     np.ndarray: Array of coefficients for each rolling window.</p>"},{"location":"/home/jose/code/MainSequenceClientSide/mainsequence-sdk/docs/reference/virtualfundbuilder/contrib/time_series/portfolio_replicator/#mainsequence.virtualfundbuilder.contrib.time_series.portfolio_replicator.rolling_lasso_regression","title":"<code>rolling_lasso_regression(y, X, window, alpha=1.0, *args, **kwargs)</code>","text":"<p>Perform rolling Lasso regression and return the coefficients.</p> <p>Parameters:     y (pd.Series): Target variable.     X (pd.DataFrame): Feature variables.     window (int): Size of the rolling window.     alpha (float, optional): Regularization strength. Defaults to 1.0.</p> <p>Returns:     list: List of DataFrames containing the coefficients for each rolling window.</p>"},{"location":"/home/jose/code/MainSequenceClientSide/mainsequence-sdk/docs/reference/virtualfundbuilder/contrib/time_series/portfolio_replicator/#mainsequence.virtualfundbuilder.contrib.time_series.portfolio_replicator.rolling_pca_betas","title":"<code>rolling_pca_betas(X, window, n_components=5, *args, **kwargs)</code>","text":"<p>Perform rolling PCA and return the betas (normalized principal component weights).</p> <p>Parameters:     X (pd.DataFrame): DataFrame of stock returns or feature data (rows are time, columns are assets).     window (int): The size of the rolling window.     n_components (int, optional): The number of principal components to extract. Defaults to 5.</p> <p>Returns:     np.ndarray: An array of normalized PCA weights for each rolling window.</p>"},{"location":"/home/jose/code/MainSequenceClientSide/mainsequence-sdk/docs/reference/virtualfundbuilder/portfolio_templates/crypto_index_template/","title":"Crypto index template","text":""},{"location":"/home/jose/code/MainSequenceClientSide/mainsequence-sdk/docs/reference/virtualfundbuilder/portfolio_templates/crypto_index_template/#mainsequence.virtualfundbuilder.portfolio_templates.crypto_index_template","title":"<code>mainsequence.virtualfundbuilder.portfolio_templates.crypto_index_template</code>","text":""},{"location":"/home/jose/code/MainSequenceClientSide/mainsequence-sdk/docs/reference/virtualfundbuilder/portfolio_templates/momentum_portfolio/","title":"Momentum portfolio","text":""},{"location":"/home/jose/code/MainSequenceClientSide/mainsequence-sdk/docs/reference/virtualfundbuilder/portfolio_templates/momentum_portfolio/#mainsequence.virtualfundbuilder.portfolio_templates.momentum_portfolio","title":"<code>mainsequence.virtualfundbuilder.portfolio_templates.momentum_portfolio</code>","text":""},{"location":"/home/jose/code/MainSequenceClientSide/mainsequence-sdk/docs/reference/virtualfundbuilder/resource_factory/app_factory/","title":"App factory","text":""},{"location":"/home/jose/code/MainSequenceClientSide/mainsequence-sdk/docs/reference/virtualfundbuilder/resource_factory/app_factory/#mainsequence.virtualfundbuilder.resource_factory.app_factory","title":"<code>mainsequence.virtualfundbuilder.resource_factory.app_factory</code>","text":""},{"location":"/home/jose/code/MainSequenceClientSide/mainsequence-sdk/docs/reference/virtualfundbuilder/resource_factory/app_factory/#mainsequence.virtualfundbuilder.resource_factory.app_factory.register_app","title":"<code>register_app(name=None, register_in_agent=True)</code>","text":"<p>Decorator to register a model class in the factory. If <code>name</code> is not provided, the class's name is used as the key.</p>"},{"location":"/home/jose/code/MainSequenceClientSide/mainsequence-sdk/docs/reference/virtualfundbuilder/resource_factory/base_factory/","title":"Base factory","text":""},{"location":"/home/jose/code/MainSequenceClientSide/mainsequence-sdk/docs/reference/virtualfundbuilder/resource_factory/base_factory/#mainsequence.virtualfundbuilder.resource_factory.base_factory","title":"<code>mainsequence.virtualfundbuilder.resource_factory.base_factory</code>","text":""},{"location":"/home/jose/code/MainSequenceClientSide/mainsequence-sdk/docs/reference/virtualfundbuilder/resource_factory/base_factory/#mainsequence.virtualfundbuilder.resource_factory.base_factory.BaseResource","title":"<code>BaseResource</code>","text":""},{"location":"/home/jose/code/MainSequenceClientSide/mainsequence-sdk/docs/reference/virtualfundbuilder/resource_factory/base_factory/#mainsequence.virtualfundbuilder.resource_factory.base_factory.BaseResource.get_source_notebook","title":"<code>get_source_notebook()</code>  <code>classmethod</code>","text":"<p>Retrieve the exact source code of the class from notebook cells.</p>"},{"location":"/home/jose/code/MainSequenceClientSide/mainsequence-sdk/docs/reference/virtualfundbuilder/resource_factory/base_factory/#mainsequence.virtualfundbuilder.resource_factory.base_factory.insert_in_registry","title":"<code>insert_in_registry(registry, cls, register_in_agent, name=None, attributes=None)</code>","text":"<p>helper for strategy decorators</p>"},{"location":"/home/jose/code/MainSequenceClientSide/mainsequence-sdk/docs/reference/virtualfundbuilder/resource_factory/base_factory/#mainsequence.virtualfundbuilder.resource_factory.base_factory.send_resource_to_backend","title":"<code>send_resource_to_backend(resource_class, attributes=None)</code>","text":"<p>Helper function to send the strategy payload to the registry. Parses the arguments of the classes init function and the init functions of the parent classes</p>"},{"location":"/home/jose/code/MainSequenceClientSide/mainsequence-sdk/docs/reference/virtualfundbuilder/resource_factory/rebalance_factory/","title":"Rebalance factory","text":""},{"location":"/home/jose/code/MainSequenceClientSide/mainsequence-sdk/docs/reference/virtualfundbuilder/resource_factory/rebalance_factory/#mainsequence.virtualfundbuilder.resource_factory.rebalance_factory","title":"<code>mainsequence.virtualfundbuilder.resource_factory.rebalance_factory</code>","text":""},{"location":"/home/jose/code/MainSequenceClientSide/mainsequence-sdk/docs/reference/virtualfundbuilder/resource_factory/rebalance_factory/#mainsequence.virtualfundbuilder.resource_factory.rebalance_factory.RebalanceStrategyBase","title":"<code>RebalanceStrategyBase</code>","text":"<p>               Bases: <code>BaseResource</code></p>"},{"location":"/home/jose/code/MainSequenceClientSide/mainsequence-sdk/docs/reference/virtualfundbuilder/resource_factory/rebalance_factory/#mainsequence.virtualfundbuilder.resource_factory.rebalance_factory.RebalanceStrategyBase.calendar","title":"<code>calendar</code>  <code>property</code>","text":"<p>Workaround due to error when pickleing the calendar</p>"},{"location":"/home/jose/code/MainSequenceClientSide/mainsequence-sdk/docs/reference/virtualfundbuilder/resource_factory/rebalance_factory/#mainsequence.virtualfundbuilder.resource_factory.rebalance_factory.RebalanceStrategyBase.__init__","title":"<code>__init__(calendar='24/7', *args, **kwargs)</code>","text":"<p>Args:     calendar (str): Trading calendar. The string should must be valid calendar from the pandas_market_calendars (like '24/7' or 'NYSE')</p>"},{"location":"/home/jose/code/MainSequenceClientSide/mainsequence-sdk/docs/reference/virtualfundbuilder/resource_factory/rebalance_factory/#mainsequence.virtualfundbuilder.resource_factory.rebalance_factory.RebalanceStrategyBase.calculate_rebalance_dates","title":"<code>calculate_rebalance_dates(start, end, calendar, rebalance_frequency_strategy)</code>","text":"<p>Determines the dates on which portfolio rebalancing should be executed based on the specified rebalancing strategy. This calculation takes into account the start time of the rebalancing window and the execution frequency.</p> <p>Args:     start (pd.DataFrame): A datetime containing the start time</p> <p>Returns:     pd.DatetimeIndex: A DatetimeIndex containing all the dates when rebalancing should occur.</p>"},{"location":"/home/jose/code/MainSequenceClientSide/mainsequence-sdk/docs/reference/virtualfundbuilder/resource_factory/rebalance_factory/#mainsequence.virtualfundbuilder.resource_factory.rebalance_factory.register_rebalance_class","title":"<code>register_rebalance_class(name=None, register_in_agent=True)</code>","text":"<p>Decorator to register a model class in the factory. If <code>name</code> is not provided, the class's name is used as the key.</p>"},{"location":"/home/jose/code/MainSequenceClientSide/mainsequence-sdk/docs/reference/virtualfundbuilder/resource_factory/signal_factory/","title":"Signal factory","text":""},{"location":"/home/jose/code/MainSequenceClientSide/mainsequence-sdk/docs/reference/virtualfundbuilder/resource_factory/signal_factory/#mainsequence.virtualfundbuilder.resource_factory.signal_factory","title":"<code>mainsequence.virtualfundbuilder.resource_factory.signal_factory</code>","text":""},{"location":"/home/jose/code/MainSequenceClientSide/mainsequence-sdk/docs/reference/virtualfundbuilder/resource_factory/signal_factory/#mainsequence.virtualfundbuilder.resource_factory.signal_factory.SignalWeightsFactory","title":"<code>SignalWeightsFactory</code>","text":"<p>               Bases: <code>BaseFactory</code></p>"},{"location":"/home/jose/code/MainSequenceClientSide/mainsequence-sdk/docs/reference/virtualfundbuilder/resource_factory/signal_factory/#mainsequence.virtualfundbuilder.resource_factory.signal_factory.SignalWeightsFactory.get_signal_weights_strategies","title":"<code>get_signal_weights_strategies()</code>  <code>staticmethod</code>","text":"<p>Scans the given directory for Python files, imports the classes, and returns all classes that are subclasses of WeightsBase.</p>"},{"location":"/home/jose/code/MainSequenceClientSide/mainsequence-sdk/docs/reference/virtualfundbuilder/resource_factory/signal_factory/#mainsequence.virtualfundbuilder.resource_factory.signal_factory.SignalWeightsFactory.get_signal_weights_strategy","title":"<code>get_signal_weights_strategy(signal_weights_name)</code>  <code>staticmethod</code>","text":"<p>Creates an instance of the appropriate SignalWeights class based on the provided name.</p>"},{"location":"/home/jose/code/MainSequenceClientSide/mainsequence-sdk/docs/reference/virtualfundbuilder/resource_factory/signal_factory/#mainsequence.virtualfundbuilder.resource_factory.signal_factory.WeightsBase","title":"<code>WeightsBase</code>","text":"<p>               Bases: <code>BaseResource</code></p>"},{"location":"/home/jose/code/MainSequenceClientSide/mainsequence-sdk/docs/reference/virtualfundbuilder/resource_factory/signal_factory/#mainsequence.virtualfundbuilder.resource_factory.signal_factory.WeightsBase.__init__","title":"<code>__init__(signal_assets_configuration, *args, **kwargs)</code>","text":"<p>Base Class for all signal weights</p> <p>Attributes:     assets_configuration (AssetsConfiguration): Configuration details for signal assets.</p>"},{"location":"/home/jose/code/MainSequenceClientSide/mainsequence-sdk/docs/reference/virtualfundbuilder/resource_factory/signal_factory/#mainsequence.virtualfundbuilder.resource_factory.signal_factory.WeightsBase.interpolate_index","title":"<code>interpolate_index(new_index)</code>","text":"<p>Get interpolated weights for a time index. Weights are only valid for a certain time, therefore forward fill is limited.</p>"},{"location":"/home/jose/code/MainSequenceClientSide/mainsequence-sdk/docs/reference/virtualfundbuilder/resource_factory/signal_factory/#mainsequence.virtualfundbuilder.resource_factory.signal_factory.register_signal_class","title":"<code>register_signal_class(name=None, register_in_agent=True)</code>","text":"<p>Decorator to register a model class in the factory. If <code>name</code> is not provided, the class's name is used as the key.</p>"},{"location":"getting_started/TDAG/","title":"Welcome to TDAG","text":"<p>TDAG is a cutting-edge, graph-based workflow orchestration tool specifically designed to simplify the creation, management, and scaling of time-series data pipelines. Unlike general-purpose orchestration tools such as Airflow or Luigi, TDAG is purpose-built with the performance, scalability, and flexibility needed for modern asset management and real-time data processing.</p>"},{"location":"getting_started/TDAG/#why-another-workflow-orchestration-tool","title":"Why Another Workflow Orchestration Tool?","text":"<p>While orchestration tools like Airflow and Luigi are widely used, they weren't originally built to handle the demanding performance and resource constraints required by modern asset management workflows. TDAG addresses these limitations by providing native support for resource management (CPU/GPU), seamless integration with databases, and built-in time-series logic that reduces boilerplate code and development overhead.</p>"},{"location":"getting_started/TDAG/#key-features-of-tdag","title":"Key Features of TDAG:","text":"<ul> <li> <p>Native Time-Series Support: Built specifically for investment management and real-time data operations, TDAG provides first-class concepts like <code>TimeSerie</code> and <code>update_statistics</code>, streamlining pipeline creation.</p> </li> <li> <p>Integrated Resource Management: TDAG enforces CPU and GPU resource constraints directly within workflow definitions, simplifying resource allocation without requiring external schedulers.</p> </li> <li> <p>Built-in Data Layer: TDAG offers integrated data-handling features (<code>update_statistics</code> and <code>get_last_observation()</code>), eliminating the need for extensive custom database interaction code.</p> </li> <li> <p>Automated Dependency Management: TDAG automatically manages complex task dependencies, significantly reducing manual setup and ensuring efficient execution.</p> </li> <li> <p>High Performance and Scalability: Optimized specifically for high-throughput environments, TDAG excels at scaling seamlessly with demanding time-series tasks.</p> </li> </ul>"},{"location":"getting_started/TDAG/#example-use-case-simple-time-series-pipeline","title":"Example Use Case: Simple Time Series Pipeline","text":"<p>Imagine a scenario where each task sequentially processes data:</p> <ul> <li>Task A: Inserts an initial value.</li> <li>Task B: Takes the output from Task A, adds 5, and inserts the result.</li> <li>Task C: Takes the output from Task B, adds another 5, and inserts the final result.</li> </ul> <p>Each of these tasks requires defined resources (e.g., 2 GPUs and 10 CPUs).</p> <p>While Luigi and Airflow can achieve this, both require significant extra setup, particularly for GPU management    and seamless database integration.    TDAG simplifies this process dramatically, embedding these features directly into workflow definitions, as demonstrated below:</p> <pre><code>from mainsequence.tdag import TimeSerie\nfrom mainsequence.tdag_client.models import DataUpdates\nimport pandas as pd\nimport datetime\n\nclass TS1(TimeSerie):\n    REQUIRED_CPUS = 10\n    REQUIRED_GPUS = 2\n\n    def update(self, update_statistics: DataUpdates):\n        data = pd.DataFrame(index=[datetime.datetime.now()], data=[100])\n        return data\n\nclass TS2(TimeSerie):\n    REQUIRED_CPUS = 10\n    REQUIRED_GPUS = 2\n\n    def __init__(self):\n        self.ts_dep = TS1()\n\n    def update(self, update_statistics: DataUpdates):\n        last_val = self.ts_dep.get_last_observation().values()[0]\n        data = pd.DataFrame(index=[datetime.datetime.now()], data=[last_val + 5])\n        return data\n\nclass TS3(TimeSerie):\n    REQUIRED_CPUS = 10\n    REQUIRED_GPUS = 2\n\n    def __init__(self):\n        self.ts_dep = TS2()\n\n    def update(self, update_statistics: DataUpdates):\n        last_val = self.ts_dep.get_last_observation().values()[0]\n        data = pd.DataFrame(index=[datetime.datetime.now()], data=[last_val + 5])\n        return data\n</code></pre>"},{"location":"getting_started/TDAG/#tdag-vs-luigi-vs-airflow","title":"TDAG vs. Luigi vs. Airflow","text":"Feature Luigi Airflow TDAG (Main Sequence) Database SQLite (local file) SQLite (local file) TimeScale or any supported database Resources Defined in Task (manual config) Defined explicitly in Executors Declared directly in classes (<code>REQUIRED_GPUS</code>) DAG Definition Python Classes with <code>requires()</code> Python Operators with <code>&gt;&gt;</code> Python Classes with automatic dependencies Scheduling External scheduler required Built-in scheduler (UI) Integrated scheduler in Main Sequence platform Execution &amp; Monitoring CLI Web Interface or CLI Main Sequence UI or CLI"},{"location":"getting_started/TDAG/#real-world-applications","title":"Real-World Applications","text":"<ul> <li>Financial modeling and investment strategies</li> <li>Real-time machine learning workflows</li> <li>Online training and predictive analytics</li> </ul> <p>TDAG ensures that your data pipelines are robust, scalable, and easy to maintain, enabling your teams to focus on generating value rather than managing infrastructure.</p>"},{"location":"getting_started/TDAG/tutorial/Introduction_part1/","title":"Part 1: TimeSeries","text":"<p>Let\u2019s start with a simple example and progressively build upon it. Suppose we want to replicate a fund for which we don\u2019t know the exact components\u2014this could be an ETF (Exchange-Traded Fund) or a closed-end fund. Since we don\u2019t know the components, we will adopt a data-driven approach to estimate the underlying assets.</p> <p>To make it more concrete, let\u2019s assume we want to replicate the S&amp;P 500 Financial Sector. A good proxy for this sector is the XLF ETF. Our goal is to replicate the performance of XLF by identifying its components using historical data. Since we don't have the exact components, we'll run a regularized rolling regression.</p> <p>For regularization, we\u2019ll use Lasso (Least Absolute Shrinkage and Selection Operator) because it has the desirable property of setting certain weights to zero due to its L1 regularization, effectively selecting only the most important assets in our replication.</p>"},{"location":"getting_started/TDAG/tutorial/Introduction_part1/#rolling-regression-with-lasso","title":"Rolling Regression with Lasso","text":""},{"location":"getting_started/TDAG/tutorial/Introduction_part1/#1-fixed-window-regression-pseudo-code","title":"1. Fixed Window Regression (Pseudo-code)","text":"<p>Before we dive into rolling regressions, let's first outline the process for a fixed window regression using Lasso:</p> <ul> <li>Collect the historical returns for XLF and the individual stocks from the S&amp;P 500 Financial Sector.</li> <li>Run the Lasso regression for a given period (e.g., last 60 days).</li> <li>Use the Lasso coefficients to identify the most important stocks for that period.</li> </ul> <p>In pseudo-code:</p> <pre><code># Pseudo-code for fixed window Lasso regression\nfor each window in historical_data:\n    X = get_returns_for_stocks_in_window(window)\n    y = get_returns_for_XLF_in_window(window)\n    model = Lasso(alpha=\u03bb)  # \u03bb is the regularization parameter\n    model.fit(X, y)\n    coefficients = model.coef_\n    select_significant_assets(coefficients)\n</code></pre>"},{"location":"getting_started/TDAG/tutorial/Introduction_part1/#2-maintainability-of-our-pipeline","title":"2. Maintainability of Our Pipeline**","text":"<p>What we want to achieve now is to write the code that performs this rolling regression and have a system that runs this code automatically, say every day at 11 PM. Additionally, we need to ensure that the results are persisted so they can be extracted, reused, and integrated into other processes. Of course, we want to accomplish this in a simple and extendable way. This is where our first Tdag Helper comes in: a TimeSerie object.</p>"},{"location":"getting_started/TDAG/tutorial/Introduction_part1/#tdag-time-series","title":"Tdag Time Series","text":"<p>In simple terms, a Tdag TimeSerie is an object of type <code>TimeSerie</code> that controls the following three main tasks:</p> <ol> <li>Updating Logic: It contains the logic for updating a time series based on its last update.</li> <li>Linked to Storage: It is linked to a storage solution. By default, we use TimeScaleDB for storing the data.</li> <li>Uniqueness Guarantee: It guarantees that the persisted data is unique for each combination of parameters.</li> </ol> <p>For example, if we have a <code>TimeSerie</code> that performs a rolling regression using the last 100 days of data, this <code>TimeSerie</code> should be different from a <code>TimeSerie</code> that uses the last 200 days. This ensures the uniqueness of each time series instance based on its specific configuration.</p> <pre><code>graph TD\n    A[TimeSerie: XLF Returns] --&gt; B[TimeSerie: Lasso Regression: 100 Days]\n    A --&gt; E[TimeSerie: Lasso Regression: 200 Days]\n\n    B --&gt; |to Timescale DB| D[DB Table for : TimeSerie: Lasso Regression: 100 Days]\n    E --&gt; |to Timescale DB| G[DB Table for : TimeSerie: Lasso Regression: 200 Days]\n\n    classDef purple fill:#DDA0DD,stroke:#000,stroke-width:2px;\n    class D purple;\n    class G purple;\n</code></pre> <p>To achieve this structure, TDAG will automatically handle the hashing process and ensure that we have two distinct sets of data based on our arguments. Let's see how we can achieve this in code.</p> <p>First, we extend the TimeSerie class with the arguments that we require; in this case, these are the size of the rolling window and the regularization parameter. The decorator <code>@TimeSerie._post_init_routines</code> is necessary to perform all the magic behind TDAG.</p> <pre><code>from mainsequence.tdag import TimeSerie\nfrom utils import BarTimeSerie\n\n\ndef get_prices_bars():\n    ...\n\n\nclass ETFReplicator(TimeSerie):\n\n    @TimeSerie._post_init_routines()\n    def __init__(self, lasso_alpha: float, in_window: int = 60, *args, **kwargs):\n        super().__init__(*args, **kwargs)\n        self.in_window = in_window\n        self.lasso_alpha = lasso_alpha\n        self.bars_ts = BarsTimeSerie()  # a time serie with the prices\n</code></pre> <p>As you can see, the initialization is quite simple. We just need to define the parameters that will uniquely define our time series: in this case, <code>lasso_alpha</code> and <code>in_window</code>. It is important to mention that we are referencing another time series with <code>BarTimeSerie</code>.</p> <p>Now the next step is to add the logic to get the coefficients. This is also quite simple. Here, we use the TimeSerie method <code>get_df_from_table_after_date</code> to retrieve only the new data that we need. Important observations are:</p> <ol> <li>If latest_value is None, it means that the time series has never been updated, so we need to handle this logic.</li> <li>We always use UTC dates in the database to ensure compatibility.</li> </ol> <pre><code>from mainsequence.tdag import TimeSerie\n\n\ndef get_lasso_coefficients():\n    ...\n\n\nclass ETFReplicator(TimeSerie):\n    def update(self, latest_value: Union[datetime, None], *args, **kwargs) -&gt; pd.DataFrame:\n        if latest_value is None:\n            latest_value = datetime.datetime(2010, 1, 1).replace(tzinfo=pytz.utc)\n        start_value = latest_value - datetime.timedelta(days=self.in_window)\n        prices = self.bars_ts.get_df_from_table_after_date(start_value)\n\n        prices = prices.reset_index().pivot_table(index='time_index', columns='asset_symbol',\n                                                  values=self.assets_configuration.price_type.value)\n        weights = get_lasso_coefficients(prices, self.lasso_alpha)\n        return weights\n</code></pre> <p>And thats all with only this lines of code this pipeline will be updated systmetaically and persisted into our database Lets get a litte more complicated. As you perhaps noticed in the previous code we are not defining at any point the asset that we want to replicate so we should add this to the initialization. Now also lets suppose that we want to build a portfolio that goes long a replication of the XLF and goes short a replication of XLE which is the energy sector of the S&amp;P500.</p> <p>Also, for the sake of stability, let\u2019s build this portfolio where each leg is the average weight of the 100-day and 200-day rolling regression. For sake of simplicit lets leave on lasso_alpha for all regression but this is something we could easily change.</p> <p>First, let\u2019s modify our initialization method to include the ticker that we want to replicate.</p> <pre><code>class ETFReplicator(TimeSerie):\n\n    @TimeSerie._post_init_routines()\n    def __init__(self, lasso_alpha: float, ticker_to_replicate: str, in_window: int = 60, *args, **kwargs):\n        super().__init__(*args, **kwargs)\n        ...\n</code></pre> <p>now lets look at how our portfolio <code>TimeSerie</code> will look like</p> <pre><code>class LongShortPortfolio(TimeSerie):\n    @TimeSerie._post_init_routines()\n    def __init__(self, ticker_long: str, ticker_short: str, long_roling_windows: list, lasso_alpha: float,\n                 short_rolling_windows: list, *args, **kwargs):\n        super().__init__(*args, **kwargs)\n        long_ts = {f\"ts_{i}\": ETFReplicator(lasso_alpha=lasso_alpha, ticker_to_replicate=ticker_long,\n                                            in_window=i\n                                            ) for i in long_roling_windows}\n        short_ts = {f\"ts_{i}\": ETFReplicator(lasso_alpha=lasso_alpha, ticker_to_replicate=ticker_long,\n                                             in_window=i\n                                             ) for i in short_rolling_windows}\n        self.long_ts = long_ts\n        self.short_ts = short_ts\n        self.lasso_alpha=lasso_alpha\n\n\nlong_short_portfolio = LongShortPortfolio(ticker_long=\"XLF\", ticker_short=\"XLE\", long_rolling_windows=[100, 200, ],\n                                          short_rolling_windows=[100, 200],lasso_alpha=1e-2\n                                          )\n</code></pre> <p>That\u2019s all! With only these few lines of code, we have a fully integrated data pipeline that will update our portfolio automatically. What is more important on this example is how you can build the pipelines as building blocks but agnostic  of how the previous block was build. you dont even neeed to know from how many other TimeSeries this block belongs.  This process make it extremely powerfull to stack while keeping a clean and lean code. </p> <p>The graph of this pipeline should look something like this:</p> <pre><code>graph TD\n    A[TimeSerie: XLF Returns] --&gt; B[TimeSerie:  XLF Lasso Regression: 100 Days]\n    A --&gt; E[TimeSerie: XLF Lasso Regression: 200 Days]\n\n    A[TimeSerie: XLF Returns] --&gt; B_1[TimeSerie:  XLE Lasso Regression: 100 Days]\n    A --&gt; E_1[TimeSerie: XLE Lasso Regression: 200 Days]\n\n\n    B --&gt; |to Timescale DB| D[DB Table for : XLF TimeSerie: Lasso Regression: 100 Days]\n    E --&gt; |to Timescale DB| G[DB Table for : XLF TimeSerie: Lasso Regression: 200 Days]\n\n    B_1 --&gt; |to Timescale DB| D_1[DB Table for : XLE TimeSerie: Lasso Regression: 100 Days]\n    E_1 --&gt; |to Timescale DB| G_1[DB Table for : XLE TimeSerie: Lasso Regression: 200 Days]\n\n    D --&gt; |to portfolio TS | last[TimeSerie: Long Short Portfolio]\n    G --&gt; |to portfolio TS| last\n\n    D_1 --&gt; |to portfolio TS | last\n    G_1 --&gt; |to portfolio TS| last\n\n    classDef purple fill:#DDA0DD,stroke:#000,stroke-width:2px;\n    class D purple;\n    class G purple;\n    class D_1 purple;\n    class G_1 purple;\n</code></pre> <p>As you can see, even with this simple example, the pipelines are becoming increasingly complex. Now imagine integrating data from a different source\u2014let\u2019s say U.S. economic data from the Federal Reserve. Perhaps you also want to interpolate or filter the prices in a specific way. What about adding sentiment analysis from internet searches? And how about a machine learning model that requires feeding with thousands of different signals and needs to be retrained every two weeks?</p> <p>This is just for one pipeline tied to a single portfolio. Now imagine wanting to maintain multiple portfolios, each tailored for different profiles. Surely, you wouldn\u2019t want to manage this using a spreadsheet or countless Jupyter notebooks, right?</p> <p>now lets look at how we can start scheduling our pipelines. continue to Part 2 Running Pipelines</p>"},{"location":"getting_started/TDAG/tutorial/running_time_series_part2/","title":"Part 2: Running Pipelines","text":"<p>In the previous section, we saw how we can build our pipelines. Now, in this section, let's look at how we can start running them. In TDAG, we have mainly three ways of running our pipelines:</p> <ol> <li>We run our pipelines as a single continuous process, persisting and reading from our database in DEBUG Mode.</li> <li>We run our pipelines as a separate distributed process, where we can scale each node in the graph into a Ray cluster.</li> <li>We can run locally using Parquet data without interacting with the database. This method is very useful for running    fast iterations before we persist something in the database. Because, as you can imagine, continuous queries to a    database within a loop can incur time overhead.</li> </ol>"},{"location":"getting_started/TDAG/tutorial/running_time_series_part2/#running-with-tdag-schedulers","title":"Running with TDAG Schedulers","text":"<p>for the first two methods we will use <code>Schedulers</code> this object is in charge of organizing and coordinating the update of time series. The reason of why we have sveral schedulers and not only one scheduler its because this helps to maintain isolated enviroments bewteen different time series even when they become to the same pipeline lets look at one example</p> <p>Making reference to our previous example we can have one scheduler that is in charge of updating all our pipeliens which uses an environment of scikit learn , while we can have another scheduler that updates pipelines on an environment that requires heavy machine learning libraries like Rapids and Pytorch in this case we will have somthing like this.</p> <pre><code>graph TD\n    A[Scheduler: For scikit learn environment] --&gt; B[TimeSerie: Type 1]\n    A --&gt; E[TimeSerie: Type 2]\n\n    E --&gt; E1[Intermediate Time Series]\n    B --&gt; B1[Intermediate Time Series]\n\n    E1 --&gt;P[TimeSeries:Prices]\n    B1 --&gt;P\n\n    A_P[Scheduler: For Nvidia environment] --&gt; B_P[TimeSerie: Type 2]\n    A_P --&gt; E_P[TimeSerie: Type 2]\n\n    E_P --&gt; E1_P[Intermediate Time Series]\n    B_P --&gt; B1_P[Intermediate Time Series]\n\n    E1_P --&gt;P\n    B1_P --&gt;P   \n\n\n\n    classDef purple fill:#DDA0DD,stroke:#000,stroke-width:2px;\n    class A purple;\n    class A_P purple;\n\n</code></pre> <p>As you can see in the example above, schedulers can have different configurations and mixed time series dependencies. If a time series is dependent on a particular environment, you can isolate it and allow a specific scheduler to update it only. You can also let a time series be updated by the next available scheduler. You don't need to worry; this all happens in the background. As you will see, setting it up is quite simple.</p>"},{"location":"getting_started/TDAG/tutorial/running_time_series_part2/#scheduler-in-debug-mode","title":"Scheduler in debug mode","text":"<p>To Run a scheduler in debug mode first you need to create the time serie that you want to run</p> <pre><code>from mainsequence.tdag import SchedulerUpdater\n\ntime_serie = ETFReplicator(lasso_alpha=.01, ticker_to_replicate=\"SPY\", in_window=100)\nSchedulerUpdater.debug_schedule_ts(\n    time_serie_hash_id=time_serie.local_hash_id,\n    break_after_one_update=True,\n    debug=True,\n    update_tree=True,\n)\n</code></pre> <p>That is all! This will start a process in which the full tree will be executed sequentially. Notice that we are using the class method <code>debug_schedule_ts</code>. What this method does is generate a new scheduler on the fly and execute the time series in this scheduler. We could also start it in the following way:</p> <pre><code>from mainsequence.tdag import SchedulerUpdater, Scheduler\n\nscheduler = Scheduler.build_and_assign_to_ts(scheduler_name=s_name, local_hash_id_list=[time_serie.local_hash_id],\n                                             delink_all_ts=False)\nSchedulerUpdater.start(scheduler=scheduler, break_after_one_update=True,\n                       debug=True,\n                       update_tree=True, )\n</code></pre> <p>Now lets dig on the arguments</p> <ul> <li>time_serie_hash_id: As discussed previously, all time series are uniquely hashed. However, there are scenarios   where we need more than one hash. For example, imagine that we have a time series that depends only on the prices of 2   stocks, and another that depends on the prices of 500. We don't want to create a table for 2 stocks and another table   for 500; what we want is to have two processes that update the same table with all our stocks. To achieve this, we can   set a property in our time series called <code>ignore_local_kwargs</code>. This property will indicate which arguments we should   ignore when creating the table, while the others will be used to hash the process. For example, like this:</li> </ul> <pre><code>graph TD\n    A[TimeSerie: updates only 2 assets prices] --&gt; B[DB Table: All Prices]\n    C[TimeSerie: updates 500 assets prices] --&gt; B[DB Table: All Prices]\n\n    classDef purple fill:#DDA0DD,stroke:#000,stroke-width:2px;\n    class B purple;\n\n</code></pre> <ul> <li>break_after_one_update: Setting this to True indicates that we want to perform only one loop rather than   continuously having the process be updated.</li> <li>debug: Run in debug mode in a single process.</li> <li>update_tree: Update all the dependencies of the time series being scheduled.</li> </ul>"},{"location":"getting_started/TDAG/tutorial/running_time_series_part2/#scheduler-in-live-mode","title":"Scheduler in live mode","text":"<p>While the scheduler in debug mode is handy for testing our pipelines, we want to harness the full power of distributed and auto-scalable systems to manage all our pipelines, regardless of their complexity. Let's go back to our original example of the ETF replicator and assume that when we update the prices, we can take advantage of parallelization.</p> <p>Imagine you are requesting prices from an API, allowing you to make batch requests using several cores instead of relying on a single loop. In this case, you may want to set the <code>TimeSerie</code> <code>BarPrices</code> to use perhaps 10 CPUs, while the other time series might use only 1 CPU. Alternatively, you might want one time series to use 10 CPUs and 1 GPU.</p> <p>This and any other configuration is possible thanks to TDAG, leveraging Ray as our cluster manager. By using Ray, we can easily distribute and parallelize our pipelines and set the requirements we need for each <code>TimeSerie</code>.</p> <p>Going back to our previous example the difference between live and debug mode can be observed in the same time serie running differently</p>"},{"location":"getting_started/TDAG/tutorial/running_time_series_part2/#scheduler-in-live-mode-graph","title":"Scheduler in live mode graph","text":"<pre><code>graph TD\n    A[TimeSerie: XLF Returns] --&gt; B[TimeSerie: XLF Lasso Regression: 100 Days]\n    A --&gt; E[TimeSerie: XLF Lasso Regression: 200 Days]\n\n    A[TimeSerie: XLE Returns] --&gt; B_1[TimeSerie: XLE Lasso Regression: 100 Days]\n    A --&gt; E_1[TimeSerie: XLE Lasso Regression: 200 Days]\n\n    B --&gt; |to Timescale DB| D[DB Table for: XLF TimeSerie: Lasso Regression: 100 Days]\n    E --&gt; |to Timescale DB| G[DB Table for: XLF TimeSerie: Lasso Regression: 200 Days]\n\n    B_1 --&gt; |to Timescale DB| D_1[DB Table for: XLE TimeSerie: Lasso Regression: 100 Days]\n    E_1 --&gt; |to Timescale DB| G_1[DB Table for: XLE TimeSerie: Lasso Regression: 200 Days]\n\n    D --&gt; |to Portfolio TS| last[TimeSerie: Long Short Portfolio]\n    G --&gt; |to Portfolio TS| last\n\n    D_1 --&gt; |to Portfolio TS| last\n    G_1 --&gt; |to Portfolio TS| last\n\n    classDef purple fill:#DDA0DD,stroke:#000,stroke-width:2px;\n    class D purple;\n    class G purple;\n    class D_1 purple;\n    class G_1 purple;\n</code></pre>"},{"location":"getting_started/TDAG/tutorial/running_time_series_part2/#scheduler-in-debug-mode-graph","title":"Scheduler in debug mode graph","text":"<pre><code>graph TD\n    A[TimeSerie: XLF Returns] --&gt; B[TimeSerie: XLF Lasso Regression: 100 Days]\n    B --&gt; C[DB Table for: XLF TimeSerie: Lasso Regression: 100 Days]\n    C --&gt; D[TimeSerie: XLF Lasso Regression: 200 Days]\n    D --&gt; E[DB Table for: XLF TimeSerie: Lasso Regression: 200 Days]\n\n\n    E--&gt; H[TimeSerie: XLE Lasso Regression: 100 Days]\n    H --&gt; I[DB Table for: XLE TimeSerie: Lasso Regression: 100 Days]\n    I --&gt; J[TimeSerie: XLE Lasso Regression: 200 Days]\n    J --&gt; K[DB Table for: XLE TimeSerie: Lasso Regression: 200 Days]\n    K --&gt; L[TimeSerie: Long Short Portfolio]\n\n    classDef purple fill:#DDA0DD,stroke:#000,stroke-width:2px;\n    class C,E,I,K purple;\n\n</code></pre>"},{"location":"getting_started/TDAG/tutorial/running_time_series_part2/#running-with-data-lake","title":"Running with Data Lake","text":"<p>While the previous two ways of running the pipelines are designed for maintainability, explorability, and clarity, we realized that there is a need for a different approach to building our pipelines that could help researchers go through the full process in a more streamlined way. This is particularly important if we want to run loops and analyses on them.</p> <p>Let\u2019s go back to our Long Short portfolio and imagine that we want to observe the hyperspace of portfolios generated by several combinations of parameters. If we fix the tickers, we have combinations of rolling windows and regularization parameters, which takes us to a four-dimensional space. In this case, we don\u2019t want to persist any iteration in the database; perhaps we just want to see at which point the interaction of the regularization parameters starts to decrease, for example, or at which point our regression starts to stabilize. For these scenarios, we can run our pipelines in Data Lake mode.</p> <p>Let\u2019s look at a code example to understand it better.</p> <pre><code>data_lake_yaml_configuration = \"\"\"\ndatalake_end: 2024-09-01 00:00:00\ndatalake_name: Long short portofolio\ndatalake_start: 2022-08-01 00:00:00\nnodes_to_get_from_db: interpolatedpricestrain_c9676700655ba6d948919ca925ca82c1\npersist_logs_to_file: false\n\"\"\"\ntotal_return = []\nfor rolling_window in range(60, 30 * 24, 20):\n    for lasso_alpha in [1, 1e-2, 1e-3, 1e-4, 1e-5]:\n        long_short_portfolio = LongShortPortfolio(ticker_long=\"XLF\", ticker_short=\"XLE\",\n                                                  long_rolling_windows=[long_rollling_window],\n                                                  short_rolling_windows=[100, 200], lasso_alpha=1e-2\n                                                  )\n        portfolio_df = long_short_portfolio.get_df_greater_than_in_table(latest_value=None)\n        total_return.append(long_short_portfolio[\"portfolio\"].iloc[-1] - 1)\n</code></pre> <p>In the previous example, if we run in Data Lake mode, each of the TimeSeries will be dumped once from the database into a Data Lake as a Parquet file. The Data Lake will be configured in a folder structure of the following form:</p> <pre><code>DataLakeName/\n\u251c\u2500\u2500 DateRange/\n\u2502   \u251c\u2500\u2500 TimeSeriesHash1/parquet_partitions\n\u2502   \u251c\u2500\u2500 TimeSeriesHash2/parquet_partitions\n\u2502   \u251c\u2500\u2500 TimeSeriesHash3/parquet_partitions\n\u2502   \u2514\u2500\u2500 ...\n\u2514\u2500\u2500 ...\n</code></pre> <p>Additionally, if we want, we can keep some TimeSeries cached in memory that are constantly being reused. This increases the speed at which we can run our pipelines by approximately 100 times, as we read mostly from memory or disk, avoiding networking and database overhead.</p> <p>To run a TimeSeries in Data Lake mode, we only need to call the method <code>get_df_greater_than_in_table</code> of the <code>TimeSerie</code> we want to calculate, and the tree will be updated automatically.</p> <p>Now, let\u2019s look at how we can visualize and manage all our pipelines in the GUI. Continue to Part 3: The TDAG Explorer.</p>"},{"location":"getting_started/TDAG/tutorial/tdag_explorer_part3/","title":"Part 3: TDAG Explorer","text":"<p>In the previous two parts we learned how can we easily build and schedule Time Series Pipelines now lets see how  can we monitor , manage and explor them in a unified web interface. </p> <p>TDAG Enterprise gives you access to complete GUI for observability in this GUI you can:</p>"},{"location":"getting_started/TDAG/tutorial/tdag_explorer_part3/#1-search-and-visualize-your-tables-by-type-of-pipeline","title":"1 Search and visualize your tables by type of pipeline","text":""},{"location":"getting_started/TDAG/tutorial/tdag_explorer_part3/#2-search-and-visualize-your-time-series-processes","title":"2 Search and visualize your Time Series Processes","text":""},{"location":"getting_started/TDAG/tutorial/tdag_explorer_part3/#search","title":"Search","text":""},{"location":"getting_started/TDAG/tutorial/tdag_explorer_part3/#visualize-its-build-and-update-detail","title":"Visualize its build and update detail","text":""},{"location":"reference/SUMMARY/","title":"SUMMARY","text":"<ul> <li>client<ul> <li>ai</li> <li>base</li> <li>data_sources_interfaces<ul> <li>local_data_lake</li> <li>timescale</li> </ul> </li> <li>models_helpers</li> <li>models_tdag</li> <li>models_vam</li> <li>utils</li> </ul> </li> <li>instrumentation<ul> <li>utils</li> </ul> </li> <li>logconf</li> <li>tdag<ul> <li>config</li> <li>distributed<ul> <li>time_series</li> <li>utils</li> </ul> </li> <li>time_series<ul> <li>persist_managers</li> <li>time_series</li> <li>update<ul> <li>api</li> <li>ray_manager</li> <li>scheduler</li> <li>update_methods</li> <li>utils</li> </ul> </li> <li>utils</li> </ul> </li> <li>utils</li> </ul> </li> <li>virtualfundbuilder<ul> <li>agent_interface</li> <li>config_handling</li> <li>contrib<ul> <li>apps<ul> <li>generate_report</li> <li>news_app</li> </ul> </li> <li>prices<ul> <li>time_series</li> <li>utils</li> </ul> </li> <li>rebalance_strategies<ul> <li>rebalance_strategies</li> </ul> </li> <li>templates<ul> <li>asset_groups</li> </ul> </li> <li>time_series<ul> <li>intraday_trend</li> <li>market_cap</li> <li>mock_signal</li> <li>portfolio_replicator</li> </ul> </li> </ul> </li> <li>enums</li> <li>models</li> <li>notebook_handling</li> <li>portfolio_interface</li> <li>portfolio_templates<ul> <li>crypto_index_template</li> <li>momentum_portfolio</li> </ul> </li> <li>resource_factory<ul> <li>app_factory</li> <li>base_factory</li> <li>rebalance_factory</li> <li>signal_factory</li> </ul> </li> <li>time_series</li> <li>utils</li> </ul> </li> </ul>"},{"location":"tdag/getting_started/","title":"Welcome to TDAG","text":"<p>TDAG  is a cutting-edge, graph-based library designed specifically for building and managing time-series data pipelines.  With TDAG, you can create automated, time-based dependency structures that are robust, efficient, and ready for real-world, scalable applications.</p> <p>At its core, TDAG leverages the power of DAGs (Directed Acyclic Graphs). A DAG is a graph with nodes connected by edges, where the edges have a direction, and no cycles (loops) exist. In simpler terms,  this structure allows data to flow in one direction without any feedback loops, which is essential for building reliable and predictable data pipelines.  The \"time-directed\" aspect in TDAG makes it ideal for handling time-sensitive operations, ensuring that tasks occur in the correct sequence.</p>"},{"location":"tdag/getting_started/#why-tdag","title":"Why TDAG?","text":"<p>With TDAG, you can automatically create time-based data pipelines that handle complex dependencies. The library provides features such as automatic hashing, seamless scheduling integration, and a structured approach that enhances the reliability and scalability of your pipelines.</p>"},{"location":"tdag/getting_started/#key-features","title":"Key Features:","text":"<ul> <li>Automated Time-Based Pipelines: TDAG allows you to easily build data pipelines where tasks are executed in time order, respecting dependencies.</li> <li>Built-in Scheduling and Hashing: Pipelines are automatically hashed and scheduled for efficient execution.</li> <li>Scalable &amp; Robust: Whether you're working on small datasets or massive time-series data flows, TDAG scales to meet your needs while ensuring the entire process is fault-tolerant and robust.</li> </ul>"},{"location":"tdag/getting_started/#use-case-investment-strategies-and-beyond","title":"Use Case: Investment Strategies and Beyond","text":"<p>One of TDAG's main use cases is transforming raw financial data into actionable insights, such as investment strategy predictions or portfolio weights. TDAG simplifies the process of managing complex time-based operations in financial modeling, helping you move from data to decisions effortlessly.</p> <p>However, TDAG is not just limited to finance! It's perfect for any application requiring time-sensitive data pipelines, particularly in live and online modes where real-time decision-making is crucial. For example, TDAG can be used in online training of machine learning models, where time-based data flow and immediate processing are essential for model accuracy and performance.</p>"},{"location":"tdag/getting_started/#why-use-a-dag","title":"Why Use a DAG?","text":"<p>A DAG (Directed Acyclic Graph) is a graph structure where: 1. Directed: Each connection (edge) between nodes points in a specific direction, indicating the flow of data or dependencies. 2. Acyclic: There are no cycles, meaning that no node in the graph can loop back to itself. This is critical for tasks that need to happen in a specific sequence.</p> <p>In the context of TDAG, a DAG ensures that all data processing happens in the correct order, and no task is repeated or stuck in a loop. When applied to time-series data pipelines, this means that your data will always flow from the past to the present in a structured, predictable manner, ensuring that dependencies are handled properly and efficiently.</p>"},{"location":"tdag/getting_started/#the-power-of-tdag","title":"The Power of TDAG","text":"<p>Whether you\u2019re managing financial data pipelines or real-time machine learning workflows, TDAG is designed to give you the control, scalability, and reliability you need to handle complex, time-sensitive data with ease.</p> <p>Start by exploring our Getting Started Tutorial or jump into the Code Reference if you're already familiar with TDAG.</p> <p>If you are looking for more resources you can also access our vidoe tutorials on TDAG here:</p>"},{"location":"tdag/orchestration_and_monitoring/","title":"Orchestration &amp; Monitoring","text":"<p>Once your time series pipelines are built, TDAG offers multiple modes for executing and monitoring their updates efficiently. These modes support local development, debugging, and scalable production deployments.</p>"},{"location":"tdag/orchestration_and_monitoring/#execution-modes","title":"Execution Modes","text":"<ol> <li>Local Mode We can run our pipeline locally using local parquet files without interacting with the remote database. This mode is ideal for fast prototyping or parameter sweeps (e.g., hyperparameter tuning). It is faster then the other modes as it does not perform costly database writes.</li> <li>Debug Mode: We run our pipelines for one-loop as a single process, persisting and reading from our remote database. This is helpful for debugging and development before moving to production.</li> <li>Live Mode: We run our pipelines as a separate distributed process via a Ray cluster. This mode is designed for production use.</li> </ol>"},{"location":"tdag/orchestration_and_monitoring/#running-time-series-in-local-mode","title":"Running Time Series in Local Mode","text":"<p>For quick local development and testing of a new time series we can use the local data lake mode to run the time serie using <pre><code>time_series = CryptoPortfolioTimeSerie()\nresult = time_series.run_local_update()\n</code></pre></p> <p>A classic use-case is to see how a strategy performs with different parameters  by running it in a loop. Here we have a Long Short portfolio and we want to observe the hyperspace of portfolios generated by several combinations of parameters. In this case, we don\u2019t want to persist any iteration in the database; perhaps we just want to see at which point the interaction of the regularization parameters starts to decrease, for example, or at which point our regression starts to stabilize. For these scenarios, we can run our pipelines in Local Mode mode.</p> <p>Let\u2019s look at a code example to understand it better.</p> <pre><code>total_return = []\nfor rolling_window in range(60, 30 * 24, 20):\n    for lasso_alpha in [1, 1e-2, 1e-3, 1e-4, 1e-5]:\n        long_short_portfolio = LongShortPortfolio(\n           ticker_long=\"XLF\", \n           ticker_short=\"XLE\",\n           long_rolling_windows=[long_rollling_window],\n           short_rolling_windows=[100, 200], \n           lasso_alpha=1e-2\n        )\n        portfolio_df = long_short_portfolio.run_local_update()\n        total_return.append(long_short_portfolio[\"portfolio\"].iloc[-1] - 1)\n</code></pre> <p>If we run in Local Mode, each of the TimeSeries will be dumped once from the database into a Data Lake as a Parquet file. The Data Lake will be configured in a folder structure of the following form:</p> <pre><code>DataLakeName/\n\u251c\u2500\u2500 DateRange/\n\u2502   \u251c\u2500\u2500 TimeSeriesHash1/parquet_partitions\n\u2502   \u251c\u2500\u2500 TimeSeriesHash2/parquet_partitions\n\u2502   \u251c\u2500\u2500 TimeSeriesHash3/parquet_partitions\n\u2502   \u2514\u2500\u2500 ...\n\u2514\u2500\u2500 ...\n</code></pre>"},{"location":"tdag/orchestration_and_monitoring/#running-time-series-in-livedebug-mode","title":"Running Time Series in Live/Debug mode","text":"<p>When we want to move our time series to production, we can execute backend system so it can be distributed and the data stored in the shared database for reusability.  This is done using the .run() method.  <pre><code>time_series = CryptoPortfolioTimeSerie()\ntime_series.run(debug_mode=False)\n</code></pre></p> <p>We can use additional parameters to specify how the timeseries should run.</p> <ul> <li><code>debug_mode</code>: A boolean Setting this to True runs the Pipeline in Debug Mode, otherwise in Live Mode.</li> <li><code>update_tree</code>: A boolean variable whether to update all the dependencies of the time series or only the called time series. This is helpful if this time series has many dependencies and we are only interested in the final time serie.</li> <li><code>update_only_tree</code>: A boolean variable whether to update only the dependencies of the time series.</li> <li><code>remote_scheduler</code>: An optional custom scheduler to run the time series. If no remote_scheduler is provided, a default scheduler is created automatically.</li> <li><code>force_update</code>: A scheduler manages at which times to run the time series. This boolean variable is used to ignore the scheduler.</li> </ul> <p>For example, to run this time series immediately in debug mode and only update the called time series, we can use: <pre><code>time_series = CryptoPortfolioTimeSerie()\ntime_series.run(debug_mode=True, update_tree=False, force_update=True)\n</code></pre></p> <p>Now, let\u2019s look at how we can visualize and manage all our pipelines in the GUI. Continue to Part 3: The TDAG Explorer.</p>"},{"location":"tdag/time_series_fundamentals/","title":"Time Series Fundamentals in TDAG","text":"<p>TDAG's core revolves around the concept of time series, encapsulated in the powerful <code>TimeSerie</code> class. Each <code>TimeSerie</code> object manages the process of updating data, reflecting the most current available information. It interacts seamlessly with databases and maintains a robust internal state, supporting efficient data pipelines.</p>"},{"location":"tdag/time_series_fundamentals/#understanding-the-update-process","title":"Understanding the Update Process","text":"<p>In TDAG, updating involves:</p> <ul> <li>Updating DataRepositories: Stores the generated data from the update process.</li> <li>Updating ORM: Manages the internal state of the data and the pipeline.</li> </ul> <p>The following diagram illustrates these interactions:</p> <pre><code>flowchart TD\n    subgraph TDAG_System[TDAG Framework]\n         TimeSerieConstructor[\"TimeSerie.__init__(*args, **kwargs)\"] --&gt;|Defines| TimeSerie[\"TimeSerie.update(latest_value)\"]\n    end\n\n    subgraph DataRepositories[\"Data Repositories\"]\n        DB[\"TimeScaleDB\"]\n        DataLake[\"DataLake\"]\n    end\n\n    subgraph ORM[\"TDAG ORM\"]\n        LocalTimeSerie[\"LocalTimeSerie (local_hash_id)\"]  --&gt;|View of Table| DynamicTable[\"DynamicTable (hash_id)\"]\n    end\n\n    TimeSerie --&gt;|Updates| DataRepositories\n    TimeSerie --&gt;|Updates| ORM\n     ORM --&gt;|Manages state of| DataRepositories\n    ORM --&gt;|Updates| DynamicTable\n    ORM --&gt;|Updates| LocalTimeSerie\n</code></pre>"},{"location":"tdag/time_series_fundamentals/#initializing-a-timeserie","title":"Initializing a TimeSerie","text":"<p>The constructor (<code>__init__</code>) defines the initial state and configuration:</p> <pre><code>def __init__(self, init_meta=None,\n             build_meta_data: Union[dict, None] = None,\n             local_kwargs_to_ignore: Union[List[str], None] = None,\n             data_configuration_path: Union[str, None] = None,\n             *args, **kwargs):\n    ...\n</code></pre>"},{"location":"tdag/time_series_fundamentals/#hashing-mechanism","title":"Hashing Mechanism","text":"<p>The constructor arguments create two essential hashes that facilitate efficient management of data and updates:</p> <ul> <li> <p><code>hash_id</code>: Used to uniquely identify data repositories linked to a specific <code>TimeSerie</code>. This ensures different configurations or datasets are appropriately separated or merged based on their content rather than their names alone.</p> </li> <li> <p><code>local_hash_id</code>: Used to uniquely identify the specific update processes. It enables TDAG to recognize distinct update routines and manage their internal state independently, crucial for parallel updates or workflows that reuse identical data structures with different update logic.</p> </li> </ul>"},{"location":"tdag/time_series_fundamentals/#special-constructor-arguments","title":"Special Constructor Arguments","text":"<p>Some arguments are explicitly excluded from hashing:</p> <ul> <li><code>init_meta</code>: Arbitrary metadata used during initialization for convenience and clarity.</li> <li><code>build_meta_data</code>: Metadata recoverable anytime and editable from interfaces; useful for dynamic or interactive data handling.</li> <li><code>local_kwargs_to_ignore</code>: Arguments excluded from the <code>hash_id</code> calculation but included in <code>local_hash_id</code>, allowing flexibility in differentiating between datasets and update processes.</li> </ul>"},{"location":"tdag/time_series_fundamentals/#decorator-usage","title":"Decorator Usage","text":"<p>Always decorate the constructor to ensure proper integration with TDAG:</p> <pre><code>from mainsequence.tdag import TimeSerie\n\nclass NewTimeSeries(TimeSerie):\n    @TimeSerie._post_init_routines\n    def __init__(self):\n        ...\n</code></pre>"},{"location":"tdag/time_series_fundamentals/#managing-dependencies-with-introspection","title":"Managing Dependencies with Introspection","text":"<p>TDAG simplifies dependency management by automatically detecting dependencies through introspection. Rather than manually managing complex dependency trees, developers only need to explicitly declare direct dependencies as class attributes. TDAG then builds the full dependency graph internally.</p> <p>Example:</p> <pre><code>class NewTimeSeries(TimeSerie):\n    @TimeSerie._post_init_routines\n    def __init__(self, asset_symbols: List[str], *args, **kwargs):\n        # Explicitly declare direct dependency\n        self.prices_time_serie = PricesTimeSerie(asset_symbols=asset_symbols)\n</code></pre> <p>TDAG automatically understands that <code>NewTimeSeries</code> depends on <code>PricesTimeSerie</code> and manages updates accordingly.</p>"},{"location":"tdag/time_series_fundamentals/#state-persistence-with-pickles","title":"State Persistence with Pickles","text":"<p>TDAG pickles each <code>TimeSerie</code> after its first initialization, significantly reducing load times in future updates. The pickle state is automatically updated when the underlying code changes, ensuring consistency and efficiency.</p>"},{"location":"tdag/time_series_fundamentals/#updating-a-timeserie","title":"Updating a TimeSerie","text":"<p>The <code>update</code> method performs all the necessary logic to fetch, calculate, and store new data points in the series. It uses a parameter called <code>latest_value</code>, representing the most recent timestamp from previous updates. If <code>latest_value</code> is <code>None</code>, the series has never been updated successfully before. Otherwise, it continues from the given point.</p> <p>Example:</p> <pre><code>def update(self, update_statistics: DataUpdates, *args, **kwargs) -&gt; pd.DataFrame:\n    # Perform update logic based on latest_value\n    new_data = self.fetch_new_data_since(latest_value)\n    processed_data = self.calculate_metrics(new_data)\n    return processed_data\n</code></pre> <p>Returned DataFrame requirements:</p> <ul> <li>Unidimensional index: <code>DatetimeIndex</code> in <code>pytz.utc</code>.</li> <li>Multidimensional index: three dimensions: <code>time_index</code>, <code>asset_symbol</code>, and <code>execution_venue_symbol</code>.</li> </ul>"},{"location":"tdag/time_series_fundamentals/#essential-helper-methods","title":"Essential Helper Methods","text":""},{"location":"tdag/time_series_fundamentals/#retrieving-data-between-dates","title":"Retrieving Data Between Dates","text":"<p>The <code>get_df_between_dates</code> method fetches data from a specified date range:</p> <pre><code>def get_df_between_dates(self, start_date: Union[datetime.datetime, None] = None,\n                         end_date: Union[datetime.datetime, None] = None,\n                         unique_identifier_list: Union[None, list] = None,\n                         great_or_equal=True, less_or_equal=True,\n                         unique_identifier_range_map: Optional[UniqueIdentifierRangeMap] = None\n                         ) -&gt; pd.DataFrame:\n</code></pre> <p>This method efficiently retrieves data within a specific range, accommodating various filtering scenarios by asset or time intervals.</p>"},{"location":"tdag/time_series_fundamentals/#getting-last-observation","title":"Getting Last Observation","text":"<pre><code>def get_last_observation(self, asset_symbols: Union[None, list] = None):\n</code></pre> <p>Returns the most recent observation in the series.</p>"},{"location":"tdag/time_series_fundamentals/#wrappertimeserie-class","title":"WrapperTimeSerie Class","text":"<p><code>WrapperTimeSerie</code> allows collective management of multiple <code>TimeSerie</code> instances, facilitating scalable and efficient updates:</p> <pre><code>class WrapperTimeSerie(TimeSerie):\n    @TimeSerie._post_init_routines()\n    def __init__(self, time_series_dict: Dict[str, TimeSerie], *args, **kwargs):\n</code></pre> <p>TDAG\u2019s TimeSeries object simplifies managing complex data dependencies, ensuring efficiency, consistency, and maintainability in your data pipelines.</p>"}]}